
<!DOCTYPE html>
<html>
  <head>
    
<meta charset="utf-8" >

<title>神经网络模型演化 | dragon</title>
<meta name="description" content="邮箱(base64)：MTY5MDMwMjk2M0BxcS5jb20=
">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://DragonFive.github.io//favicon.ico?v=1630418948363">
<link rel="stylesheet" href="https://DragonFive.github.io//styles/main.css">



<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>



  </head>
  <body>
    <div id="app" class="main">
      <div class="site-header-container">
  <div class="site-header">
    <div class="left">
      <a href="https://DragonFive.github.io/">
        <img class="avatar" src="https://DragonFive.github.io//images/avatar.png?v=1630418948363" alt="" width="32px" height="32px">
      </a>
      <a href="https://DragonFive.github.io/">
        <h1 class="site-title">dragon</h1>
      </a>
    </div>
    <div class="right">
      <transition name="fade">
        <i class="icon" :class="{ 'icon-close-outline': menuVisible, 'icon-menu-outline': !menuVisible }" @click="menuVisible = !menuVisible"></i>
      </transition>
    </div>
  </div>
</div>

<transition name="fade">
  <div class="menu-container" style="display: none;" v-show="menuVisible">
    <div class="menu-list">
      
        
          <a href="/" class="menu purple-link">
            首页
          </a>
        
      
        
          <a href="/archives" class="menu purple-link">
            归档
          </a>
        
      
        
          <a href="/tags" class="menu purple-link">
            标签
          </a>
        
      
        
          <a href="/post/about" class="menu purple-link">
            关于
          </a>
        
      
    </div>
  </div>
</transition>


      <div class="content-container">
        <div class="post-detail">
          
          <h2 class="post-title">神经网络模型演化</h2>
          <div class="post-info post-detail-info">
            <span><i class="icon-calendar-outline"></i> 2017-07-05</span>
            
              <span>
                <i class="icon-pricetags-outline"></i>
                
                  <a href="https://DragonFive.github.io/tag/o9zBQ9B4NY/">
                    神经网络
                    
                  </a>
                
              </span>
            
          </div>
          <div class="post-content">
            <hr>
<p>title: 神经网络模型演化<br>
date: 2017/7/5 17:38:58</p>
<p>categories:</p>
<ul>
<li>深度学习<br>
tags:</li>
<li>deeplearning</li>
<li>alexnet</li>
<li>googlenet</li>
<li>caffenet</li>
<li>caffe</li>
</ul>
<hr>
<p>[TOC]</p>
<ol>
<li>Lenet，1986年</li>
<li>Alexnet，2012年</li>
<li>GoogleNet，2014年</li>
<li>VGG，2014年</li>
<li>Deep Residual Learning，2015年</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1503832736486.jpg" alt="caffe model" loading="lazy"></figure>
<h1 id="网络结构的基础知识">网络结构的基础知识</h1>
<ol>
<li>下采样层的目的是为了<strong>降低网络训练参数</strong>及模型的<strong>过拟合程度</strong>。</li>
<li>LRN局部响应归一化有利于模型泛化。（过拟合）</li>
<li>alexnet做了重叠池化，与lenet不同。也就是说它的pool kernel的步长比kernel size要小。</li>
<li>dropout在每个不同的样本进来的时候用不同的一半的神经元做fc层。但他们共享权重，</li>
<li>relu是线性的，非饱和的。收敛速度比sigmoid和tanh快</li>
<li>inception的主要思路是用密集成分来近似局部稀疏结构。网络越到后面，特征越来越抽象，3x3、5x5的卷积的比例也在增加，但是5x5的卷积计算量会大，后续层的参数会多，因此需要用1x1的卷积进行降维</li>
</ol>
<h2 id="alexnet">alexNet</h2>
<p>它证明了CNN在复杂模型下的有效性，然后GPU实现使得训练在可接受的时间范围内得到结果<br>
Alexnet有一个特殊的计算层，LRN层，做的事是对当前层的输出结果做平滑处理。</p>
<p>前面的结构  conv - relu - pool - LRN</p>
<figure data-type="image" tabindex="2"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1502709541017.jpg" alt="卷积层" loading="lazy"></figure>
<p>全连接的结构 fc - relu - dropout</p>
<h2 id="googlenet">googLeNet</h2>
<p>从这里开始pooling层其实变少了。<br>
要想提高CNN的网络能力，比如分类准确率，一般的想法就是增大网络，比如Alexnet确实比以前早期Lenet大了很多，但是纯粹的增大网络——比如把<strong>每一层的channel数量翻倍</strong>——但是这样做有两个缺点——<strong>参数太多容易过拟合，网络计算量也会越来越大</strong>。</p>
<h3 id="inception-v1">inception v1</h3>
<figure data-type="image" tabindex="3"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1502709248613.jpg" alt="inceptionv1结构" loading="lazy"></figure>
<p>一分四，然后做一些不同大小的卷积，之后再堆叠feature map。这样提取不同尺度的特征，能够提高网络表达能力。</p>
<p>目前很多工作证明，要想增强网络能力，可以：增加网络深度，增加网络宽度；但是为了<strong>减少过拟合，也要减少自由参数</strong>。因此，就自然而然有了这个第一版的Inception网络结构——同一层里面，有卷积1x1, 3x 3,5x 5 <strong>不同的卷积模板，他们可以在不同size的感受野做特征提取</strong>，也算的上是一种混合模型了。因为<strong>Max Pooling本身也有特征提取的作用</strong>，而且和卷积不同，没有参数不会过拟合，也作为一个分支。但是直接这样做，整个网络计算量会较大，且层次并没有变深，因此，在3x3和5x5卷 积前面<strong>先做1x1的卷积，降低input的channel数量，这样既使得网络变深，同时计算量反而小了</strong>；（在每一个卷积之后都有<strong>ReLU</strong>）</p>
<h3 id="inception-v2-v3">inception v2 v3</h3>
<p>用1x3和3x1卷积替代3x3卷积，计算量少了很多，深度变深，思路是一样的。（实际上是1xn和nx1替代nxn，n可以变）,使用的是不对称的卷积核</p>
<figure data-type="image" tabindex="4"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1502710845336.jpg" alt="incepiton v2" loading="lazy"></figure>
<figure data-type="image" tabindex="5"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1502710981337.jpg" alt="incpiton 2网络结构" loading="lazy"></figure>
<h2 id="vgg">VGG</h2>
<p>特点也是连续conv多，计算量巨大</p>
<figure data-type="image" tabindex="6"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1502710007686.jpg" alt="做连续卷积" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1505876579495.jpg" alt="VGG的参数量" loading="lazy"></figure>
<h2 id="resnet">resnet</h2>
<p>特殊之处在于设计了“bottleneck”形式的block（有跨越几层的直连）。最深的model采用的152层</p>
<p>block的结构如下图</p>
<figure data-type="image" tabindex="8"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1502710123203.jpg" alt="block" loading="lazy"></figure>
<h2 id="global-average-pooling">Global Average Pooling</h2>
<p>在Googlenet网络中，也用到了Global Average Pooling，其实是受启发于Network In Network。Global Average Pooling一般用于放在网络的最后，用于替换全连接FC层，为什么要替换FC？因为在使用中，例如alexnet和vgg网络都在卷积和softmax之间串联了fc层，发现有一些缺点：</p>
<p>（1）<strong>参数量极大</strong>，有时候一个网络超过80~90%的参数量在最后的几层FC层中；<br>
（2）<strong>容易过拟合</strong>，很多CNN网络的过拟合主要来自于最后的fc层，因为参数太多，却没有合适的regularizer；过拟合导致模型的泛化能力变弱；<br>
（3）实际应用中非常重要的一点，paper中并没有提到：<strong>FC要求输入输出是fix的</strong>，也就是说图像必须按照给定大小，而实际中，图像有大有小，fc就很不方便；</p>
<p>作者提出了Global Average Pooling，做法很简单，是对<strong>每一个单独的feature map取全局average</strong>。要求输出的nodes和分类category数量一致，这样后面就可以直接接softmax了。</p>
<p>global avg pooling层没有参数所以不会过拟合。</p>
<h1 id="reference">reference</h1>
<p><a href="http://blog.csdn.net/xbinworld/article/details/61674836">深度学习方法（十一）：卷积神经网络结构变化</a></p>
<p><a href="http://blog.csdn.net/xbinworld/article/details/61210499">卷积神经网络结构变化</a></p>
<p><a href="http://www.shuang0420.com/2017/04/25/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20%E7%AC%94%E8%AE%B0(%E9%AB%98%E7%BA%A7%E7%AF%87)/">卷积神经网络总结</a></p>

          </div>
        </div>

        
          <div class="next-post">
            <a class="purple-link" href="https://DragonFive.github.io/post/caffe_study/">
              <h3 class="post-title">
                下一篇：caffe-源码学习——只看一篇就够了
              </h3>
            </a>
          </div>
          
      </div>

      

      <div class="site-footer">
  <div class="slogan">邮箱(base64)：MTY5MDMwMjk2M0BxcS5jb20=
</div>
  <div class="social-container">
    
      
        <a href="https://github.com/DragonFive" target="_blank">
          <i class="fab fa-github"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
  </div>
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
</div>


    </div>
    <script type="application/javascript">

hljs.initHighlightingOnLoad()

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>




  </body>
</html>
