<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://DragonFive.github.io/</id>
    <title>dragon</title>
    <updated>2021-05-28T03:36:47.216Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://DragonFive.github.io/"/>
    <link rel="self" href="https://DragonFive.github.io/atom.xml"/>
    <subtitle>Code is cheap, show me the theory</subtitle>
    <logo>https://DragonFive.github.io/images/avatar.png</logo>
    <icon>https://DragonFive.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, dragon</rights>
    <entry>
        <title type="html"><![CDATA[从编译器的辅助信息看c++对象内存布局]]></title>
        <id>https://DragonFive.github.io/post/cpp-memory/</id>
        <link href="https://DragonFive.github.io/post/cpp-memory/">
        </link>
        <updated>2019-02-17T04:16:29.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>Title: 从编译器的辅助信息看c++对象内存布局<br>
date: 2019/02/17 14:28:58<br>
categories:</p>
<ul>
<li>编程<br>
tags:</li>
<li>cpp</li>
</ul>
<hr>
<h1 id="预知识">预知识</h1>
<p>本文的内容使用的是32位的编译器编译出的结果，可以打印出类的内存布局信息</p>
<h2 id="devcpp-ide">DevCPP IDE</h2>
<p>这个IDE是我比较喜欢的windows下的cpp的IDE之一，它有一个工具-&gt;编译选项，可以选择编译器类型，也可以在编译选项中加入一些信息，为了能够输出内存布局信息，我在编译时加入以下命令</p>
<pre><code class="language-cpp">--std=c++11  -fdump-class-hierarchy 
</code></pre>
<p>-fdump-class-hierarchy 这个选项能够在gcc编译时生成类的布局信息，生成的文件名类似为6.cpp.002t.class</p>
<h2 id="vs2017">vs2017</h2>
<p>vs使用的编译器是cl，它的命令为<br>
/d1reportAllClassLayout： 输出所有类相关布局</p>
<h2 id="clang">clang</h2>
<p>clang -Xclang -fdump-record-layouts</p>
<h2 id="理解内存布局信息">理解内存布局信息</h2>
<p>测试代码如下</p>
<pre><code class="language-cpp">class father{
	int a;
	int b;
};

class child: public father{
};

int main(){
	return 0;
}
</code></pre>
<p>使用 g++ -fdump-class-hierarchy test.cpp 生成了 test.cpp.002t.class内容如下</p>
<pre><code>Class father
   size=8 align=4
   base size=8 base align=4
father (0x0x16662d8) 0

Class child
   size=8 align=4
   base size=8 base align=4
child (0x0x3984e00) 0
  father (0x0x1666310) 0
</code></pre>
<p>显示了类的大小和对齐信息。</p>
<h2 id="题话外-理解内存对齐">题话外: 理解内存对齐</h2>
<ol>
<li>结构体第一个成员的偏移量（offset）为0，以后每个成员相对于结构体首地址的 offset 都是该成员大小与有效对齐值中较小那个的整数倍，如有需要编译器会在成员之间加上填充字节。</li>
<li>结构体的总大小为 有效对齐值 的整数倍，如有需要编译器会在最末一个成员之后加上填充字节。</li>
</ol>
<h1 id="多态与虚表">多态与虚表</h1>
<p>多态，简单来说，是指在继承层次中，父类的指针可以具有多种形态——当它指向某个子类对象时，通过它能够调用到子类的函数，而非父类的函数。</p>
<p>虚函数指针一般都放在对象内存布局的第一个位置上，这是为了保证在多层继承或多重继承的情况下能以最高效率取到虚函数表。当vprt位于对象内存最前面时，<strong>对象的地址即为虚函数指针地址</strong>。我们可以取得<strong>虚函数指针的地址</strong>。</p>
<p>下面的方式取得虚函数指针的地址（而非虚函数指针指向的地址）</p>
<pre><code class="language-cpp">Base b(1000);
int * vptrAdree = (int *)(&amp;b);
</code></pre>
<p>vptrAdree指向了虚函数指针（指向虚函数表），</p>
<p>而我们可以通过如下的方式获得第一个虚函数的地址</p>
<pre><code class="language-cpp">Base b(1000);
using fun=void(*) ();
fun fun1 = (fun)*((int *)*(int *)(&amp;b));
fun fun2 = (fun)*((int *)*(int *)(&amp;c)+1);
</code></pre>
<h2 id="简单的情况单层继承与虚函数全覆盖">简单的情况，单层继承与虚函数全覆盖</h2>
<p>通过查看编译器生成的内存布局信息来具体地看：</p>
<pre><code class="language-cpp">#include &lt;iostream&gt;
using namespace std;

class Base{
	int a;
	virtual int print(){
		cout&lt;&lt;&quot; i am base&quot;&lt;&lt;endl;
	}
	virtual int print2(){
		cout&lt;&lt;&quot; i am base2&quot; &lt;&lt;endl;
	}
}; 

class child: public Base{
	int print(){
		cout&lt;&lt; &quot; i am the child&quot; &lt;&lt;endl;	
	}
	int print2(){
		cout&lt;&lt;&quot; i am the child2&quot; &lt;&lt;endl;
	}
};



int  main(){
	Base testBase;
	//using fun=int(*)();
	typedef int(*fun) (void);
	fun print=(fun)*((int *)*(int *)(&amp;testBase));
	print();
	cout&lt;&lt;(int *)*(int *)(&amp;testBase)&lt;&lt;endl;
	cout&lt;&lt;((int *)*(int *)(&amp;testBase))+1&lt;&lt;endl;
	fun pprint2 = (fun)*((int *)*(int *)(&amp;testBase)+1);
	pprint2();
	return 0;
} 
</code></pre>
<p>g++编译后生成的内存布局信息为：</p>
<pre><code class="language-cpp">Vtable for Base
Base::_ZTV4Base: 4u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI4Base)
8     (int (*)(...))Base::print
12    (int (*)(...))Base::print2

Class Base
   size=8 align=4
   base size=8 base align=4
Base (0x0x4e057a8) 0
    vptr=((&amp; Base::_ZTV4Base) + 8u)

Vtable for child
child::_ZTV5child: 4u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI5child)
8     (int (*)(...))child::print
12    (int (*)(...))child::print2

Class child
   size=8 align=4
   base size=8 base align=4
child (0x0x4e4b280) 0
    vptr=((&amp; child::_ZTV5child) + 8u)
  Base (0x0x4e057e0) 0
      primary-for child (0x0x4e4b280)
</code></pre>
<p>Vtable表示的是虚函数表，可以发现Vtable for Base里面保存了vptr， 而且位置是vptr=((&amp; Base::_ZTV4Base) + 8u)（注意这里加了8的偏移），这个位置的第一个内容就是(int (*)(...))Base::print。</p>
<h2 id="复杂的情况多重继承与部分虚函数覆盖">复杂的情况：多重继承与部分虚函数覆盖</h2>
<pre><code class="language-cpp">#include &lt;iostream&gt;
using namespace std;
class Parent {
public:
    int iparent;
    Parent ():iparent (10) {}
    virtual void g() { cout &lt;&lt; &quot; Parent::g()&quot; &lt;&lt; endl; }
    virtual void f() { cout &lt;&lt; &quot; Parent::f()&quot; &lt;&lt; endl; }
    virtual void h() { cout &lt;&lt; &quot; Parent::h()&quot; &lt;&lt; endl; }
 
};
 
class Child : public Parent {
public:
    int ichild;
    Child():ichild(100) {}
    virtual void g_child() { cout &lt;&lt; &quot;Child::g_child()&quot; &lt;&lt; endl; }
    virtual void h_child() { cout &lt;&lt; &quot;Child::h_child()&quot; &lt;&lt; endl; }
    virtual void f() { cout &lt;&lt; &quot;Child::f()&quot; &lt;&lt; endl; }
};
 
class GrandChild : public Child{
public:
    int igrandchild;
    GrandChild():igrandchild(1000) {}
    virtual void g_child() { cout &lt;&lt; &quot;GrandChild::g_child()&quot; &lt;&lt; endl; }
    virtual void f() { cout &lt;&lt; &quot;GrandChild::f()&quot; &lt;&lt; endl; }
    virtual void h_grandchild() { cout &lt;&lt; &quot;GrandChild::h_grandchild()&quot; &lt;&lt; endl; }
};
int main(){
	typedef void(*Fun)(void);
	GrandChild gc;	 
	int** pVtab = (int**)&amp;gc;
	 
	cout &lt;&lt; &quot;[0] GrandChild::_vptr-&gt;&quot; &lt;&lt; endl;
	for (int i=0; (Fun)pVtab[0][i]!=NULL; i++){
	    Fun pFun = (Fun)pVtab[0][i];
	    cout &lt;&lt; &quot;    [&quot;&lt;&lt;i&lt;&lt;&quot;] &quot;;
	    pFun();
	}
	cout &lt;&lt; &quot;[1] Parent.iparent = &quot; &lt;&lt; (int)pVtab[1] &lt;&lt; endl;
	cout &lt;&lt; &quot;[2] Child.ichild = &quot; &lt;&lt; (int)pVtab[2] &lt;&lt; endl;
	cout &lt;&lt; &quot;[3] GrandChild.igrandchild = &quot; &lt;&lt; (int)pVtab[3] &lt;&lt; endl;
} 
</code></pre>
<p>内存布局信息如下</p>
<pre><code class="language-cpp">Vtable for Parent
Parent::_ZTV6Parent: 5u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI6Parent)
8     (int (*)(...))Parent::g
12    (int (*)(...))Parent::f
16    (int (*)(...))Parent::h

Class Parent
   size=8 align=4
   base size=8 base align=4
Parent (0x0x4de37a8) 0
    vptr=((&amp; Parent::_ZTV6Parent) + 8u)

Vtable for Child
Child::_ZTV5Child: 7u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI5Child)
8     (int (*)(...))Parent::g
12    (int (*)(...))Child::f
16    (int (*)(...))Parent::h
20    (int (*)(...))Child::g_child
24    (int (*)(...))Child::h_child

Class Child
   size=12 align=4
   base size=12 base align=4
Child (0x0x4e2a5c0) 0
    vptr=((&amp; Child::_ZTV5Child) + 8u)
  Parent (0x0x4de37e0) 0
      primary-for Child (0x0x4e2a5c0)

Vtable for GrandChild
GrandChild::_ZTV10GrandChild: 8u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI10GrandChild)
8     (int (*)(...))Parent::g
12    (int (*)(...))GrandChild::f
16    (int (*)(...))Parent::h
20    (int (*)(...))GrandChild::g_child
24    (int (*)(...))Child::h_child
28    (int (*)(...))GrandChild::h_grandchild

Class GrandChild
   size=16 align=4
   base size=16 base align=4
GrandChild (0x0x4e2aa80) 0
    vptr=((&amp; GrandChild::_ZTV10GrandChild) + 8u)
  Child (0x0x4e2aac0) 0
      primary-for GrandChild (0x0x4e2aa80)
    Parent (0x0x4de3818) 0
        primary-for Child (0x0x4e2aac0)


</code></pre>
<p>通过查看可以发现，子类的虚函数表里面的优先级是先父类，再子类再孙类，同一优先级按照声明顺序排地址，即使父类的虚函数被覆盖了，也要写在原来的位置，这样能够保证，父类的指针能按照函数名找到那个地址。</p>
<p>程序的执行结果为：</p>
<pre><code class="language-cpp">[0] GrandChild::_vptr-&gt;
&lt;pre&gt;    [0] GrandChild::f()
    [1] Parent::g()
    [2] Parent::h()
    [3] GrandChild::g_child()
    [4] Child::h1()
    [5] GrandChild::h_grandchild()
[1] Parent.iparent = 10
[2] Child.ichild = 100
[3] GrandChild.igrandchild = 1000

</code></pre>
<p>可知</p>
<ol>
<li>虚函数表在最前面的位置。</li>
<li>成员变量根据其继承和声明顺序依次放在后面。</li>
<li>在单一的继承中，被overwrite的虚函数在虚函数表中得到了更新。</li>
</ol>
<h2 id="多重继承">多重继承</h2>
<pre><code class="language-cpp">#include &lt;iostream&gt;
using namespace std;
class Base1 {
public:
    int ibase1;
    Base1():ibase1(10) {}
    virtual void f() { cout &lt;&lt; &quot;Base1::f()&quot; &lt;&lt; endl; }
    virtual void g() { cout &lt;&lt; &quot;Base1::g()&quot; &lt;&lt; endl; }
    virtual void h() { cout &lt;&lt; &quot;Base1::h()&quot; &lt;&lt; endl; }
 
};
 
class Base2 {
public:
    int ibase2;
    Base2():ibase2(20) {}
    virtual void f() { cout &lt;&lt; &quot;Base2::f()&quot; &lt;&lt; endl; }
    virtual void g() { cout &lt;&lt; &quot;Base2::g()&quot; &lt;&lt; endl; }
    virtual void h() { cout &lt;&lt; &quot;Base2::h()&quot; &lt;&lt; endl; }
};
 
class Base3 {
public:
    int ibase3;
    Base3():ibase3(30) {}
    virtual void f() { cout &lt;&lt; &quot;Base3::f()&quot; &lt;&lt; endl; }
    virtual void g() { cout &lt;&lt; &quot;Base3::g()&quot; &lt;&lt; endl; }
    virtual void h() { cout &lt;&lt; &quot;Base3::h()&quot; &lt;&lt; endl; }
};
 
class Derive : public Base1, public Base2, public Base3 {
public:
    int iderive;
    Derive():iderive(100) {}
    virtual void f() { cout &lt;&lt; &quot;Derive::f()&quot; &lt;&lt; endl; }
    virtual void g1() { cout &lt;&lt; &quot;Derive::g1()&quot; &lt;&lt; endl; }
};
int main(){
	typedef void(*Fun)(void);
	 
	Derive d;
	 
	int** pVtab = (int**)&amp;d;
	 
	cout &lt;&lt; &quot;[0] Base1::_vptr-&gt;&quot; &lt;&lt; endl;
	Fun pFun = (Fun)pVtab[0][0];
	cout &lt;&lt; &quot;     [0] &quot;;
	pFun();
	 
	pFun = (Fun)pVtab[0][1];
	cout &lt;&lt; &quot;     [1] &quot;;pFun();
	 
	pFun = (Fun)pVtab[0][2];
	cout &lt;&lt; &quot;     [2] &quot;;pFun();
	 
	pFun = (Fun)pVtab[0][3];
	cout &lt;&lt; &quot;     [3] &quot;; pFun();
	 
	pFun = (Fun)pVtab[0][4];
	cout &lt;&lt; &quot;     [4] &quot;; cout&lt;&lt;pFun&lt;&lt;endl;
	 
	cout &lt;&lt; &quot;[1] Base1.ibase1 = &quot; &lt;&lt; (int)pVtab[1] &lt;&lt; endl;
	 
	int s = sizeof(Base1)/4;
	 
	cout &lt;&lt; &quot;[&quot; &lt;&lt; s &lt;&lt; &quot;] Base2::_vptr-&gt;&quot;&lt;&lt;endl;
	pFun = (Fun)pVtab[s][0];
	cout &lt;&lt; &quot;     [0] &quot;; pFun();
	 
	pFun = (Fun)pVtab[s][1];
	cout &lt;&lt; &quot;     [1] &quot;; pFun();
	 
	pFun = (Fun)pVtab[s][2];
	cout &lt;&lt; &quot;     [2] &quot;; pFun();
	 
	pFun = (Fun)pVtab[s][3];
	cout &lt;&lt; &quot;     [3] &quot;;
	cout&lt;&lt;pFun&lt;&lt;endl;
	 
	cout &lt;&lt; &quot;[&quot;&lt;&lt; s+1 &lt;&lt;&quot;] Base2.ibase2 = &quot; &lt;&lt; (int)pVtab[s+1] &lt;&lt; endl;
	 
	s = s + sizeof(Base2)/4;
	 
	cout &lt;&lt; &quot;[&quot; &lt;&lt; s &lt;&lt; &quot;] Base3::_vptr-&gt;&quot;&lt;&lt;endl;
	pFun = (Fun)pVtab[s][0];
	cout &lt;&lt; &quot;     [0] &quot;; pFun();
	 
	pFun = (Fun)pVtab[s][1];
	cout &lt;&lt; &quot;     [1] &quot;; pFun();
	 
	pFun = (Fun)pVtab[s][2];
	cout &lt;&lt; &quot;     [2] &quot;; pFun();
	 
	pFun = (Fun)pVtab[s][3];
	cout &lt;&lt; &quot;     [3] &quot;;
	cout&lt;&lt;pFun&lt;&lt;endl;
	 
	s++;
	cout &lt;&lt; &quot;[&quot;&lt;&lt; s &lt;&lt;&quot;] Base3.ibase3 = &quot; &lt;&lt; (int)pVtab[s] &lt;&lt; endl;
	s++;
	cout &lt;&lt; &quot;[&quot;&lt;&lt; s &lt;&lt;&quot;] Derive.iderive = &quot; &lt;&lt; (int)pVtab[s] &lt;&lt; endl;
	return 0; 
} 

</code></pre>
<p>内存分布情况如下</p>
<pre><code class="language-cpp">Vtable for Base1
Base1::_ZTV5Base1: 5u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI5Base1)
8     (int (*)(...))Base1::f
12    (int (*)(...))Base1::g
16    (int (*)(...))Base1::h

Class Base1
   size=8 align=4
   base size=8 base align=4
Base1 (0x0x4d907a8) 0
    vptr=((&amp; Base1::_ZTV5Base1) + 8u)

Vtable for Base2
Base2::_ZTV5Base2: 5u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI5Base2)
8     (int (*)(...))Base2::f
12    (int (*)(...))Base2::g
16    (int (*)(...))Base2::h

Class Base2
   size=8 align=4
   base size=8 base align=4
Base2 (0x0x4d907e0) 0
    vptr=((&amp; Base2::_ZTV5Base2) + 8u)

Vtable for Base3
Base3::_ZTV5Base3: 5u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI5Base3)
8     (int (*)(...))Base3::f
12    (int (*)(...))Base3::g
16    (int (*)(...))Base3::h

Class Base3
   size=8 align=4
   base size=8 base align=4
Base3 (0x0x4d90818) 0
    vptr=((&amp; Base3::_ZTV5Base3) + 8u)

Vtable for Derive
Derive::_ZTV6Derive: 16u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI6Derive)
8     (int (*)(...))Derive::f
12    (int (*)(...))Base1::g
16    (int (*)(...))Base1::h
20    (int (*)(...))Derive::g1
24    (int (*)(...))-8
28    (int (*)(...))(&amp; _ZTI6Derive)
32    (int (*)(...))Derive::_ZThn8_N6Derive1fEv
36    (int (*)(...))Base2::g
40    (int (*)(...))Base2::h
44    (int (*)(...))-16
48    (int (*)(...))(&amp; _ZTI6Derive)
52    (int (*)(...))Derive::_ZThn16_N6Derive1fEv
56    (int (*)(...))Base3::g
60    (int (*)(...))Base3::h

Class Derive
   size=28 align=4
   base size=28 base align=4
Derive (0x0x4ddeb40) 0
    vptr=((&amp; Derive::_ZTV6Derive) + 8u)
  Base1 (0x0x4d90850) 0
      primary-for Derive (0x0x4ddeb40)
  Base2 (0x0x4d90888) 8
      vptr=((&amp; Derive::_ZTV6Derive) + 32u)
  Base3 (0x0x4d908c0) 16
      vptr=((&amp; Derive::_ZTV6Derive) + 52u)

</code></pre>
<p>程序的输出结果为</p>
<pre><code class="language-cpp">[0] Base1::_vptr-&gt;
     [0] Derive::f()
     [1] Base1::g()
     [2] Base1::h()
     [3] Derive::g1()
     [4] 1
[1] Base1.ibase1 = 10
[2] Base2::_vptr-&gt;
     [0] Derive::f()
     [1] Base2::g()
     [2] Base2::h()
     [3] 1
[3] Base2.ibase2 = 20
[4] Base3::_vptr-&gt;
     [0] Derive::f()
     [1] Base3::g()
     [2] Base3::h()
     [3] 0
[5] Base3.ibase3 = 30
[6] Derive.iderive = 100

</code></pre>
<p>结论：</p>
<ol>
<li>每个父类都有自己的虚表。</li>
<li>子类的成员函数被放到了第一个父类的表中。</li>
<li>内存布局中，其父类布局依次按声明顺序排列。</li>
<li>每个父类的虚表中的f()函数都被overwrite成了子类的f()。这样做就是为了解决不同的父类类型的指针指向同一个子类实例，而能够调用到实际的函数。</li>
</ol>
<h2 id="多重继承-2">多重继承</h2>
<pre><code class="language-cpp">#include &lt;iostream&gt;
using namespace std;
class B
{
    public:
        int ib;
        char cb;
    public:
        B():ib(0),cb('B') {}
 
        virtual void f() { cout &lt;&lt; &quot;B::f()&quot; &lt;&lt; endl;}
        virtual void Bf() { cout &lt;&lt; &quot;B::Bf()&quot; &lt;&lt; endl;}
};
class B1 :  public B
{
    public:
        int ib1;
        char cb1;
    public:
        B1():ib1(11),cb1('1') {}
 
        virtual void f() { cout &lt;&lt; &quot;B1::f()&quot; &lt;&lt; endl;}
        virtual void f1() { cout &lt;&lt; &quot;B1::f1()&quot; &lt;&lt; endl;}
        virtual void Bf1() { cout &lt;&lt; &quot;B1::Bf1()&quot; &lt;&lt; endl;}
 
};
class B2:  public B
{
    public:
        int ib2;
        char cb2;
    public:
        B2():ib2(12),cb2('2') {}
 
        virtual void f() { cout &lt;&lt; &quot;B2::f()&quot; &lt;&lt; endl;}
        virtual void f2() { cout &lt;&lt; &quot;B2::f2()&quot; &lt;&lt; endl;}
        virtual void Bf2() { cout &lt;&lt; &quot;B2::Bf2()&quot; &lt;&lt; endl;}
 
};
 
class D : public B1, public B2
{
    public:
        int id;
        char cd;
    public:
        D():id(100),cd('D') {}
 
        virtual void f() { cout &lt;&lt; &quot;D::f()&quot; &lt;&lt; endl;}
        virtual void f1() { cout &lt;&lt; &quot;D::f1()&quot; &lt;&lt; endl;}
        virtual void f2() { cout &lt;&lt; &quot;D::f2()&quot; &lt;&lt; endl;}
        virtual void Df() { cout &lt;&lt; &quot;D::Df()&quot; &lt;&lt; endl;}
 
};
int main(){
	typedef void(*Fun)(void);
	int** pVtab = NULL;
	Fun pFun = NULL;
	 
	D d;
	pVtab = (int**)&amp;d;
	cout &lt;&lt; &quot;[0] D::B1::_vptr-&gt;&quot; &lt;&lt; endl;
	pFun = (Fun)pVtab[0][0];
	cout &lt;&lt; &quot;     [0] &quot;;    pFun();
	pFun = (Fun)pVtab[0][1];
	cout &lt;&lt; &quot;     [1] &quot;;    pFun();
	pFun = (Fun)pVtab[0][2];
	cout &lt;&lt; &quot;     [2] &quot;;    pFun();
	pFun = (Fun)pVtab[0][3];
	cout &lt;&lt; &quot;     [3] &quot;;    pFun();
	pFun = (Fun)pVtab[0][4];
	cout &lt;&lt; &quot;     [4] &quot;;    pFun();
	pFun = (Fun)pVtab[0][5];
	cout &lt;&lt; &quot;     [5] 0x&quot; &lt;&lt; pFun &lt;&lt; endl;
	 
	cout &lt;&lt; &quot;[1] B::ib = &quot; &lt;&lt; (int)pVtab[1] &lt;&lt; endl;
	cout &lt;&lt; &quot;[2] B::cb = &quot; &lt;&lt; static_cast&lt;char&gt;((int)(pVtab[2]))&lt;&lt; endl;
	cout &lt;&lt; &quot;[3] B1::ib1 = &quot; &lt;&lt; (int)pVtab[3] &lt;&lt; endl;
	cout &lt;&lt; &quot;[4] B1::cb1 = &quot; &lt;&lt; (char)(int)pVtab[4] &lt;&lt; endl;
	 
	cout &lt;&lt; &quot;[5] D::B2::_vptr-&gt;&quot; &lt;&lt; endl;
	pFun = (Fun)pVtab[5][0];
	cout &lt;&lt; &quot;     [0] &quot;;    pFun();
	pFun = (Fun)pVtab[5][1];
	cout &lt;&lt; &quot;     [1] &quot;;    pFun();
	pFun = (Fun)pVtab[5][2];
	cout &lt;&lt; &quot;     [2] &quot;;    pFun();
	pFun = (Fun)pVtab[5][3];
	cout &lt;&lt; &quot;     [3] &quot;;    pFun();
	pFun = (Fun)pVtab[5][4];
	cout &lt;&lt; &quot;     [4] 0x&quot; &lt;&lt; pFun &lt;&lt; endl;
	 
	cout &lt;&lt; &quot;[6] B::ib = &quot; &lt;&lt; (int)pVtab[6] &lt;&lt; endl;
	cout &lt;&lt; &quot;[7] B::cb = &quot; &lt;&lt; (char)(int)pVtab[7] &lt;&lt; endl;
	cout &lt;&lt; &quot;[8] B2::ib2 = &quot; &lt;&lt; (int)pVtab[8] &lt;&lt; endl;
	cout &lt;&lt; &quot;[9] B2::cb2 = &quot; &lt;&lt; (char)(int)pVtab[9] &lt;&lt; endl;
	 
	cout &lt;&lt; &quot;[10] D::id = &quot; &lt;&lt; (int)pVtab[10] &lt;&lt; endl;
	cout &lt;&lt; &quot;[11] D::cd = &quot; &lt;&lt; (char)(int)pVtab[11] &lt;&lt; endl;
	return 0; 
} 


</code></pre>
<p>内存分布情况如下</p>
<pre><code class="language-cpp">Vtable for B
B::_ZTV1B: 4u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI1B)
8     (int (*)(...))B::f
12    (int (*)(...))B::Bf

Class B
   size=12 align=4
   base size=9 base align=4
B (0x0x4dc27a8) 0
    vptr=((&amp; B::_ZTV1B) + 8u)

Vtable for B1
B1::_ZTV2B1: 6u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI2B1)
8     (int (*)(...))B1::f
12    (int (*)(...))B::Bf
16    (int (*)(...))B1::f1
20    (int (*)(...))B1::Bf1

Class B1
   size=20 align=4
   base size=17 base align=4
B1 (0x0x4e09780) 0
    vptr=((&amp; B1::_ZTV2B1) + 8u)
  B (0x0x4dc27e0) 0
      primary-for B1 (0x0x4e09780)

Vtable for B2
B2::_ZTV2B2: 6u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI2B2)
8     (int (*)(...))B2::f
12    (int (*)(...))B::Bf
16    (int (*)(...))B2::f2
20    (int (*)(...))B2::Bf2

Class B2
   size=20 align=4
   base size=17 base align=4
B2 (0x0x4e09c40) 0
    vptr=((&amp; B2::_ZTV2B2) + 8u)
  B (0x0x4dc2818) 0
      primary-for B2 (0x0x4e09c40)

Vtable for D
D::_ZTV1D: 14u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI1D)
8     (int (*)(...))D::f
12    (int (*)(...))B::Bf
16    (int (*)(...))D::f1
20    (int (*)(...))B1::Bf1
24    (int (*)(...))D::f2
28    (int (*)(...))D::Df
32    (int (*)(...))-20
36    (int (*)(...))(&amp; _ZTI1D)
40    (int (*)(...))D::_ZThn20_N1D1fEv
44    (int (*)(...))B::Bf
48    (int (*)(...))D::_ZThn20_N1D2f2Ev
52    (int (*)(...))B2::Bf2

Class D
   size=48 align=4
   base size=45 base align=4
D (0x0x4e27040) 0
    vptr=((&amp; D::_ZTV1D) + 8u)
  B1 (0x0x4e27080) 0
      primary-for D (0x0x4e27040)
    B (0x0x4dc2850) 0
        primary-for B1 (0x0x4e27080)
  B2 (0x0x4e270c0) 20
      vptr=((&amp; D::_ZTV1D) + 40u)
    B (0x0x4dc2888) 20
        primary-for B2 (0x0x4e270c0)


</code></pre>
<p>输出结果为</p>
<pre><code class="language-bash">[0] D::B1::_vptr-&gt;
     [0] D::f()
     [1] B::Bf()
     [2] D::f1()
     [3] B1::Bf1()
     [4] D::f2()
     [5] 0x1
[1] B::ib = 0
[2] B::cb = B
[3] B1::ib1 = 11
[4] B1::cb1 = 1
[5] D::B2::_vptr-&gt;
     [0] D::f()
     [1] B::Bf()
     [2] D::f2()
     [3] B2::Bf2()
     [4] 0x0
[6] B::ib = 0
[7] B::cb = B
[8] B2::ib2 = 12
[9] B2::cb2 = 2
[10] D::id = 100
[11] D::cd = D

</code></pre>
<p>运行结果为：</p>
<pre><code class="language-cpp">
</code></pre>
<p>发现最顶端的父类B其成员变量和虚函数存在于B1和B2中，并被D给继承下去了。而在D中，其有B1和B2的实例，于是B的成员在D的实例中存在两份，一份是B1继承而来的，另一份是B2继承而来的，因此就会浪费内存。</p>
<p>尽管我们可以通过明确指明调用路径以消除二义性，但二义性的潜在性还没有消除，我们可以通过虚继承来使D类只拥有一个ib实体。</p>
<h1 id="虚继承">虚继承</h1>
<p>虚继承解决了菱形继承中最派生类拥有多个间接父类实例的情况。虚继承的派生类的内存布局与普通继承很多不同，主要体现在：</p>
<ol>
<li>虚继承的子类，如果本身定义了新的虚函数，则编译器为其生成一个虚函数指针（vptr）以及一张虚函数表。该vptr位于对象内存最前面。vs非虚继承：直接扩展父类虚函数表。</li>
<li>虚继承的子类也单独保留了父类的vprt与虚函数表。这部分内容接与子类内容以一个四字节的0来分界。</li>
<li>虚继承的子类对象中，含有四字节的虚表指针偏移值。</li>
</ol>
<h2 id="简单虚继承">简单虚继承</h2>
<pre><code class="language-cpp">#include &lt;iostream&gt;
using namespace std;
class B
{
public:
    int ib;
public:
    B(int i=1) :ib(i){}
    virtual void f() { cout &lt;&lt; &quot;B::f()&quot; &lt;&lt; endl; }
    virtual void Bf() { cout &lt;&lt; &quot;B::Bf()&quot; &lt;&lt; endl; }
};
 
class B1 : virtual public B
{
public:
    int ib1;
public:
    B1(int i = 100 ) :ib1(i) {}
    virtual void f() { cout &lt;&lt; &quot;B1::f()&quot; &lt;&lt; endl; }
    virtual void f1() { cout &lt;&lt; &quot;B1::f1()&quot; &lt;&lt; endl; }
    virtual void Bf1() { cout &lt;&lt; &quot;B1::Bf1()&quot; &lt;&lt; endl; }
};
int main(){
	B1 b;
	using Fun=void(*)();
	Fun pFun = NULL;
	int ** pvtable = (int**)&amp;b;
	for (int i=0; i&lt;9; i++){
		if (pvtable[0][i]==NULL) {
			cout&lt;&lt;&quot;here:&quot;&lt;&lt;(int)pvtable[0][i]&lt;&lt;endl;
			i+=4;
			continue;
		}
		pFun = (Fun)pvtable[0][i];
		pFun();
	}
	cout&lt;&lt;&quot;size == &quot;&lt;&lt;sizeof(b)&lt;&lt;endl;
	cout&lt;&lt;&quot;[1]:B1::ib1=&quot;&lt;&lt;(int)pvtable[1]&lt;&lt;endl;
	cout&lt;&lt;&quot;[3]:B::ib=&quot;&lt;&lt;(int)pvtable[3]&lt;&lt;endl;
	cout&lt;&lt;&quot;[2]:B::ib=&quot;&lt;&lt;(int)pvtable[2]&lt;&lt;endl;
//	pFun = (Fun)pvtable[2];
//	pFun();
//	for (int i=1; pvtable[1][i]!=NULL; i++){
//		pFun = (Fun)pvtable[1][i];
//		pFun();
//	}
	
	return 0; 
} 



</code></pre>
<p>内存布局</p>
<pre><code class="language-cpp">Vtable for B
B::_ZTV1B: 4u entries
0     (int (*)(...))0
4     (int (*)(...))(&amp; _ZTI1B)
8     (int (*)(...))B::f
12    (int (*)(...))B::Bf

Class B
   size=8 align=4
   base size=8 base align=4
B (0x0x4f527a8) 0
    vptr=((&amp; B::_ZTV1B) + 8u)

Vtable for B1
B1::_ZTV2B1: 12u entries
0     8u
4     (int (*)(...))0
8     (int (*)(...))(&amp; _ZTI2B1)
12    (int (*)(...))B1::f
16    (int (*)(...))B1::f1
20    (int (*)(...))B1::Bf1
24    0u
28    4294967288u
32    (int (*)(...))-8
36    (int (*)(...))(&amp; _ZTI2B1)
40    (int (*)(...))B1::_ZTv0_n12_N2B11fEv
44    (int (*)(...))B::Bf

VTT for B1
B1::_ZTT2B1: 2u entries
0     ((&amp; B1::_ZTV2B1) + 12u)
4     ((&amp; B1::_ZTV2B1) + 40u)

Class B1
   size=16 align=4
   base size=8 base align=4
B1 (0x0x4f9a540) 0
    vptridx=0u vptr=((&amp; B1::_ZTV2B1) + 12u)
  B (0x0x4f527e0) 8 virtual
      vptridx=4u vbaseoffset=-12 vptr=((&amp; B1::_ZTV2B1) + 40u)

</code></pre>
<p>程序运行结果</p>
<pre><code class="language-cpp">B1::f()
B1::f1()
B1::Bf1()
here:0
B::Bf()
size == 16
[1]:B1::ib1=100
[3]:B::ib=1
[2]:B::ib=4781096

</code></pre>
<p>这里的内存分布比较奇怪，与vc++的结果不一样。</p>
<p>但是这里size是16 说明有两个指针；</p>
<h2 id="多重虚继承">多重虚继承</h2>
<p>菱形虚拟继承下，最派生类D类的对象模型又有不同的构成了。在D类对象的内存构成上，有以下几点：</p>
<ol>
<li>在D类对象内存中，基类出现的顺序是：先是B1（最左父类），然后是B2（次左父类），最后是B（虚祖父类）</li>
<li>D类对象的数据成员id放在B类前面，两部分数据依旧以0来分隔。</li>
<li>编译器没有为D类生成一个它自己的vptr，而是覆盖并扩展了最左父类的虚基类表，与简单继承的对象模型相同。</li>
<li>超类B的内容放到了D类对象内存布局的最后。</li>
</ol>
<h1 id="参考资料">参考资料</h1>
<p><a href="https://zhuanlan.zhihu.com/p/30007037">C/C++内存对齐详解</a></p>
<p><a href="https://coolshell.cn/articles/12176.html">C++ 对象的内存布局——coolshell</a></p>
<p><a href="https://www.cnblogs.com/QG-whz/p/4909359.html">图说C++对象模型：对象内存布局详解</a></p>
<p>[各编译器显示内存布局](</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ 的类型回顾]]></title>
        <id>https://DragonFive.github.io/post/cpp-innnertype/</id>
        <link href="https://DragonFive.github.io/post/cpp-innnertype/">
        </link>
        <updated>2018-09-10T04:13:39.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>Title: c++ 的类型回顾<br>
date: 2018/9/10 17:38:58<br>
categories:</p>
<ul>
<li>编程<br>
tags:</li>
<li>cpp</li>
<li>类型</li>
</ul>
<hr>
<p>C++标准规定了每个算术类型的最小存储空间，但它并不阻止编译器使用更大的存储空间。事实上，对于 int 类型，几乎所有的编译器使用的存储空间都比所要求的(16字节)大。</p>
<h1 id="c语言和c的内存管理">c语言和c++的内存管理</h1>
<p><a href="https://www.cnblogs.com/JCSU/articles/1051579.html">c语言和c++的内存管理 </a></p>
<ul>
<li>c语言分四个区：堆，栈，全局区和常量区</li>
<li>c++分五个区: 堆、栈、全局区、常量区和自由存储区<br>
c++的自由存取区类似于c语言的堆，存放的是malloc创建的内存，</li>
</ul>
<h1 id="基本类型">基本类型</h1>
<p><strong>字符类型</strong><br>
字符类型有两种：char 和 wchar_t。char 类型保证了有足够的空间，能够存储机器基本字符集中任何字符相应的数值，因此，char 类型通常是单个机器字节（byte）。wchar_t 类型用于扩展字符集，比如汉字和日语，这些字符集中的一些字符不能用单个 char 表示。<br>
<strong>整数型</strong><br>
short、int 和 long 类型都表示整型值，存储空间的大小不同。一般， short类型为半个机器字长，int 类型为一个机器字长，而 long 类型为一个或两个机器字长（在 32 位机器中 int 类型和 long 类型通常字长是相同的）。<br>
<strong>浮点型</strong><br>
对于实际的程序来说，float 类型精度通常是不够的——float 型只能保证 6 位有效数字，而 double 型至少可以保证 10 位有效数字，能满足大多数计算的需要。</p>
<h1 id="字面量">字面量</h1>
<p>只有<strong>内置类型存在字面值</strong>，没有类类型的字面值。因此，也没有任何标准库类型的字面值。<br>
<strong>整型字面值</strong><br>
整型字面量可以有三种进制的表示：十进制、八进制和十六进制。以 0（零）开头的字面值整数常量表示八进制，以 0x 或 0X 开头的表示十六进制。</p>
<p>字面值整数常量的类型默认为 int 或 long 类型。其精度类型决定于字面值——其值适合 int 就是 int 类型，比 int 大的值就是 long 类型。通过<strong>增加后缀</strong>，能够强制将字面值整数常量转换，在数值后面加 L 或者 l（字母“l”大写或小写）指定常量为 long 类型。在数值后面加 U 或 u 定义 unsigned 类型。同时加 L 和 U就能够得到 unsigned long 类型的字面值常量 。</p>
<p>用十进制或者科学计数法来表示浮点字面值常量。使用科学计数法时，指数用 E 或者 e 表示。默认的浮点字面值常量为 double 类型。在数值的后面加上 F 或 f 表示单精度。同样加上 L 或者 l 表示扩展精度.  1e-3f  表示的是0.001.<br>
<strong>字符型字面量</strong><br>
在字符字面值前加 L 就能够得到 wchar_t类型的宽字符字面值。L'a'<br>
<strong>字符串字面值</strong><br>
字符串字面值常量用双引号括起来的零个或者多个字符表示。为了兼容 C 语言，C++ 中所有的字符串字面值都由<em>编译器</em>自动在末尾添加一个空字符。&quot;A&quot; 表示包含字母 A 和空字符两个字符的字符串。 也存在宽字符串字面值，一样在前面加“L”，如 L&quot;a wide string literal&quot;宽字符串字面值是一串常量宽字符，同样以一个宽空字符结束。</p>
<p>两个相邻的仅由空格、制表符或换行符分开的字符串字面值（或宽字符串字面值），可连接成一个新字符串字面值。这使得多行书写长字符串字面值变得简单：</p>
<pre><code class="language-CPP">string a = &quot;123&quot;
           &quot;456&quot;;
</code></pre>
<h1 id="变量">变量</h1>
<p><strong>变量名规则</strong><br>
变量名必须以字母或下划线开头，并且区分大小写字母。<code>char _；</code><br>
<strong>初始化多个变量</strong><br>
当一个定义中定义了两个以上变量的时候，每个变量都可能有自己的初始化式。 对象的名字立即变成可见，所以可以用同一个定义中前面已定义变量的值初始化后面的变量。</p>
<pre><code class="language-CPP">double salary = 9999.99, wage(salary + 0.01); 
</code></pre>
<p>内置类型的变量只有在全局定义时才会被自动初始化为0， 而类的对象定义时如果没有指定构造函数，不管是全局定义还是局部定义都会调用默认构造函数。</p>
<h1 id="引用类型">引用类型</h1>
<p>引用(非const型)必须用与该引用同类型的对象初始化。<br>
<strong>定义多个引用</strong><br>
在一行中定义多个引用时，每个名字签名前都必须带&amp;，这一点与指针相似，因为它们都是复合类型</p>
<pre><code class="language-CPP">int i=1024, j=2048;
int &amp;a=i, &amp;b=j;
</code></pre>
<p><strong>const引用</strong><br>
const引用是指向const对象的引用，不能用非const引用指向const对象，const引用当然也可以指向非const对象的引用。</p>
<blockquote>
<p>非const引用只能绑定到与该引用同类型的对象。const引用则可以绑定到不同但相关类型的对象（多态或支持隐式类型转换）或绑定到字面值常量上（这就是有限的两个引用不同类型的例子）。</p>
</blockquote>
<pre><code class="language-cpp">const int a = 1;
int b = 2;
int &amp;c=a; //会报错
const int &amp;d=b ; //正确
const int &amp;e = a; //正确
const int &amp;f = 1; // 正确
int &amp;g = 1; // 错误
auto &amp;h=a; //正确 auto会保留底层const 
auto &amp;i=b; // 正确
auto &amp;j=1; //错误，字面值需要指明const
const auto &amp;k=1; //正确
</code></pre>
<p>对比，最后两个表达式，我们知道编译器可以从右值的对象中推断出底层const，却无法从字面量中推出，所以字面量必须显式指出const auto；</p>
<p>当指向不同类型的对象时，会临时创建一个对象进行类型转换。</p>
<h1 id="指针类型">指针类型</h1>
<p><strong>指针与引用的区别</strong></p>
<ol>
<li>指针是一个对象，所以可以有赋值、取地址等操作，所以可以有指向指针的引用。</li>
<li>不强制必须初始化</li>
</ol>
<p>除了两种例外情况外，其它所有指针的类型都要和它所指向的对象严格匹配<br>
例外1. const对象的指针指向同类型的非const对象（比引用严格，引用可以不同类型）<br>
例外2. 多态的场合</p>
<p><strong>空指针</strong><br>
c++11建议 使用字面值常量nullptr来将一个指针初始化为空指针</p>
<pre><code class="language-cpp">int *a=nullptr;
</code></pre>
<p>等价于 int *a=0;<br>
以前的程序用的NULL其实是一个预处理变量，这个变量定义在头文件cstdlib中，<br>
c++建议初始化所有的指针，而常量指针在定义的时候必须初始化。</p>
<h1 id="class与-struct">class与 struct</h1>
<blockquote>
<p>用class和struct关键字定义类的唯一差别在于默认访问级别：默认情况下，struct的成员为public，而class的成员为private——《c++ primer》</p>
</blockquote>
<p><strong>类的定义</strong><br>
类的定义可以放在头文件里面。</p>
<blockquote>
<p>头文件一般不包含定义，只包含extern 变量的声明和函数的声明。有三个例外：类的定义、值在编译时就知道的const对象和inline函数——《c++ primer》</p>
</blockquote>
<p>当我们在头文件中定义了const变量后，每个包含这个头文件的源文件都有了自己的const变量，当该const变量是用常量表达式初始化时，编译器在编译时会用常量表达式替换这些const变量，所以不会为每个源文件创建const对象的存储空间。而当是用函数返回值或其它内容对const变量进行初始化时，编译期间并不知道其值，所以就必须为其分配存储空间，同时该const变量也不能定义在头文件中。</p>
<h1 id="类型别名">类型别名</h1>
<p>typedef和using都能定义类型别名</p>
<pre><code class="language-CPP">typedef double wages;
using wages=double;
</code></pre>
<p>如果某个类型别名指代的是符合类型或常量，那么把它用到声明语句中就会产生意想不到的后果。</p>
<pre><code class="language-CPP">char tmp='a';
typedef char *  pstring;
const pstring cstr=&amp;tmp;
*cstr='b';
cstr=nullptr;
pstring const cstr2=&amp;tmp;
*cstr2='b';
cstr2=nullptr;
</code></pre>
<p>其实cstr1和cstr2是同样类型的对象。</p>
<h1 id="auto">auto</h1>
<blockquote>
<p>C++ 是静态类型（statically typed）语言，在编译时执行类型检查。结果是程序中使用某个名字之前，必须先告知编译器该名字的类型——《c++ primer》</p>
</blockquote>
<p>auto的对象必须初始化，auto能在一条语句中，声明多个变量。一条声明语句只能由一个基本数据类型。auto可以推断出指针，却推不出引用，必须用auto &amp;来定义一个引用。</p>
<pre><code class="language-cpp">auto i = 0, *p = &amp;i;
</code></pre>
<p>auto的对象的类型有时候会和初始值的类型不完全一致<br>
<strong>auto与引用</strong><br>
当用来为auto对象初始化的值是引用类型的时候，auto对象的类型是真正参与初始化的对象的值。<br>
设置一个类型为auto的引用时，初始值终点顶层常量属性仍然保留</p>
<pre><code class="language-cpp">const int a = 0;
int b = 0;
auto &amp;b = a; // b是const int 类型的引用
auto c = a;   // c是int类型
auto *d = &amp;a, &amp;e = b; // 编译出出错，因为&amp;a是const int的地址，而b是int

</code></pre>
<p><strong>auto与const</strong><br>
auto一般会忽略掉顶层const，同时底层const会被保留，比如当初始值是一个指向常量的指针时。</p>
<pre><code class="language-cpp">const int ci = 0, &amp;cr = ci; 
auto a = &amp;ci; // 这时候a是const int * 类型的
auto b = cr; // b是int类型的 
auto &amp;c = ci; // c是const int &amp; 类型的，因为是底层const 

</code></pre>
<p>如果希望推断出的auto类型是一个顶层const，则需要明确指出。</p>
<pre><code class="language-cpp">const auto f = ci;

</code></pre>
<h1 id="decltype">decltype</h1>
<p>c++11 引入了第二种类型说明符 decltype，它的作用是返回表达式返回值的类型，但是不会实际计算表达式的值。</p>
<p>decltype 遇到解引用操作将返回引用类型，引用类型的变量定义的时候必须初始化</p>
<pre><code class="language-cpp">int a;
int *p=&amp;a;
decltype(*p) c=a; //注意这里必须初始化

</code></pre>
<p>decltype与变量，decltype((var))返回的是引用类型，decltype(var)返回的是正常类型。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ 的关键字回顾]]></title>
        <id>https://DragonFive.github.io/post/cpp-keyword/</id>
        <link href="https://DragonFive.github.io/post/cpp-keyword/">
        </link>
        <updated>2018-09-03T04:15:07.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>Title: c++ 的关键字回顾<br>
date: 2018/9/03 17:38:58<br>
categories:</p>
<ul>
<li>编程<br>
tags:</li>
<li>cpp</li>
<li>关键字</li>
</ul>
<hr>
<p>2013年的时候写了一些学c++时候的经验<a href="https://blog.csdn.net/zhzz2012/article/details/46346115">由底层和逻辑深入剖析c++系列</a>，<br>
两年前写了一篇<a href="https://zhuanlan.zhihu.com/p/21930436">c++11新特性详解</a>，<br>
去年总结了一些c++的一些使用技巧 <a href="https://mxl.bitcron.com/post/engineering/cpp_new_feature">c++使用7年后的经验总结</a>。<br>
现在看来需要经常复习使用，才能更好地掌握c++这门编程语言。</p>
<h1 id="关键字">关键字</h1>
<h2 id="static与extern-c">static与extern &quot;C&quot;</h2>
<p><strong>区别</strong><br>
这两个是不能同时使用的一对词。</p>
<ol>
<li>
<p>static 修饰的名字只能在当前模块中使用，且不能被extern所修饰</p>
</li>
<li>
<p>extern &quot;C&quot; 表示修饰的名字来自其它模块，且要按C语言的方式进行编译和链接<br>
<strong>extern &quot;C&quot;从问题中学习</strong></p>
</li>
<li>
<p>既然c++是C的超集，为什么还要用C语言的方式编译和链接？<br>
&gt; 因为可能编写c语言的人给你的不是源代码。而是编译之后的.so文件</p>
</li>
<li>
<p>extern &quot;C&quot; 与 extern 是什么关系</p>
<blockquote>
<p>extern &quot;C&quot;包含双重含义，从字面上可以知道，首先，被它修饰的目标是&quot;extern&quot;的；其次，被它修饰的目标代码是&quot;C&quot;的。extern 告诉编译器，其申明的函数和变量可以在本模块或其他模块中使用。</p>
</blockquote>
</li>
<li>
<p>什么是按C语言的方式进行编译和链接</p>
<blockquote>
<p>函数被C++编译后在符号库中的名字是与C语言不同的；C++编译后的函数需要加上参数的类型才能唯一标定重载后的函数，而加上extern &quot;C&quot;后，是为了向编译器指明这段代码按照C语言的方式进行编译和链接。比如对于<code>int foo(int x, int y)</code>C++会编译为类似<code>__foo_int_int_</code>的形式，而c语言则会编译为<code>__foo__</code>的形式。</p>
</blockquote>
</li>
<li>
<p>在c语言中想要C++类里面的东西怎么办</p>
<blockquote>
<p><a href="https://www.cnblogs.com/Yogurshine/p/3913073.html">C代码中如何调用C++ C++中如何调用C</a><br>
<a href="https://blog.csdn.net/caspiansea/article/details/9676153">如何用C语言封装 C++的类，在 C里面使用</a></p>
</blockquote>
</li>
</ol>
<p><strong>extern &quot;C&quot;从例子中学</strong><br>
1.修饰单个句子</p>
<pre><code class="language-CPP">extern &quot;C&quot; double sqrt(double);
</code></pre>
<ol start="2">
<li>修饰复合句子</li>
</ol>
<pre><code class="language-C">extern &quot;C&quot;
 {
      double sqrt(double);
      int min(int, int);
  }
</code></pre>
<p>3.包含include头文件，相当于头文件中的声明都加了 extern &quot;C&quot;</p>
<pre><code class="language-C">extern &quot;C&quot;
{
     #include &lt;cmath&gt;
}
</code></pre>
<p>4.在C语言的一些标准头文件里经常有这样的表示</p>
<pre><code class="language-CPP">#ifdef  __cplusplus
extern &quot;C&quot; {
#endif
……// (C函数声明)
#ifdef  __cplusplus
}
#endif
</code></pre>
<p><strong>参考资料</strong><br>
<a href="https://blog.csdn.net/jiqiren007/article/details/5933599">extern C的作用详解</a></p>
<h2 id="const关键字">const关键字</h2>
<p><strong>常量指针与指针常量</strong></p>
<ol>
<li>区分方法：从右向左读 <code>char * const A</code>, A是一个不可变的指针，指向的是char数据，<code>char const * B</code> , 表示B是一个指针，这个指针指向char常量；</li>
<li>对于常量指针，不能通过该指针来改变所指的内容(可以通过其它方式修改)<br>
<strong>常量对象与常量成员函数</strong><br>
一个类的常量对象只能调用该类的常量成员函数，因为常量成员函数不能修改对象的成员变量，当然可以在一个成员变量前加上mutable关键字，这样常量成员函数就能修改它了。 <code>void func() const</code></li>
</ol>
<p><strong>常量成员变量与类常量</strong><br>
常量成员变量是说，它是属于对象的不可变的变量，所以初始化只能在构造函数的初始化列表里。const数据成员只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类声明中初始化const数据成员，因为类的对象未被创建时，编译器不知道const 数据成员的值是什么。</p>
<p>要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现。</p>
<pre><code class="language-CPP">class A
{
 enum {size1=100, size2 = 200 };
 int array1[size1];
 int array2[size2];
}
</code></pre>
<p><strong>const修饰函数返回值</strong><br>
一般用const修饰返回值为对象本身（非引用和指针）的情况多用于二目操作符重载函数并产生新对象的时候。 防止产生的临时对象被赋值。<br>
比如两个复数的乘法</p>
<pre><code class="language-CPP">const Rational operator*(const Rational&amp; lhs, const Rational&amp; rhs) 
{ 
 return Rational(lhs.numerator() * rhs.numerator(), 
 lhs.denominator() * rhs.denominator()); 
}
</code></pre>
<p>这样做可以预防出现<code>(a*b) = c</code>的情况。<br>
<strong>引用传递的返回值不要用const修饰</strong><br>
在类的本地操作符（=，&lt;&lt;等）重载函数中，函数返回值常采用“引用传递”，目的是为了实现链式表达。</p>
<pre><code class="language-CPP">class A
{
 A &amp;operate = (const A &amp;other);  //赋值函数
}
A a,b,c;              //a,b,c为A的对象
a=b=c;            //正常
(a=b)=c;          //不正常，但是合法
</code></pre>
<p>若赋值函数的返回值加const修饰，那么该返回值的内容不允许修改。所以一般赋值函数都不会这样设置。<br>
<strong>C语言与CPP中const的区别</strong></p>
<ol>
<li>C++中的const正常情况下是看成编译期的常量,编译器并不为const分配空间,只是在编译的时候将期值保存在名字表中,并在适当的时候折合在代码中，而c语言认为是不变的变量，在编译期不知道值。</li>
</ol>
<p>C++中,是否为const分配空间要看具体情况.如果加上关键字extern或者取const变量地址,则编译器就要为const分配存储空间，下面的代码在c++中会通过，而c语言不会通过</p>
<pre><code class="language-CPP">const int a=10;
int b[a];
</code></pre>
<p>2.C++中,const默认使用内部连接，定义时必须初始化(类中的成员变量除外)，或者使用extern修饰. 而C中使用外部连接，可以只声明不初始化<code>const int size;</code></p>
<p><strong>顶层const与底层const</strong><br>
是用const修饰时，如果修饰的是定义的变量就是顶层const，如果修饰的是定义的变量指向的对象那就是底层const。<br>
值得注意的是顶层const在初始化和赋值的时候，等号左右两边的对象是否const并无影响。<br>
而底层const赋值的时候，可以把非常量赋值给指向常量对象的地址，却不可以把常量初始化给指向非常量对象的地址。</p>
<p><strong>constexpr变量</strong><br>
c++11标准规定，允许将变量声明为constexpr类型，以便由编译器来验证变量的值是否是一个常量表达式</p>
<p><strong>使用const的建议</strong></p>
<ol>
<li>要大胆的使用const，这将给你带来无尽的益处，但前提是你必须搞清楚原委；</li>
<li>在参数中使用const应该使用引用或指针，而不是一般的对象实例；</li>
<li>不要轻易的将函数的返回值类型定为const;</li>
<li>除了重载操作符外一般不要将返回值类型定为对某个对象的const引用;</li>
</ol>
<blockquote>
<p>非 const 变量默认为 extern。要使 const 变量能够在其他的文件中访问，必须地指定它为 extern——《cpp primer》</p>
</blockquote>
<p><strong>参考资料</strong><br>
<a href="https://www.cnblogs.com/yc_sunniwell/archive/2010/07/14/1777416.html">c/c++中的const关键字</a><br>
《c++ primer 第五版》</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[深度学习框架的并行优化方法小结]]></title>
        <id>https://DragonFive.github.io/post/deeplearning-parrel/</id>
        <link href="https://DragonFive.github.io/post/deeplearning-parrel/">
        </link>
        <updated>2018-08-11T08:17:26.000Z</updated>
        <summary type="html"><![CDATA[<hr>
<p>title: 深度学习框架的并行优化方法小结<br>
date: 2018/8/11 17:38:58</p>
<p>categories:</p>
<ul>
<li>深度学习<br>
tags:</li>
<li>deeplearning</li>
<li>mpi</li>
<li>caffe</li>
</ul>
<hr>
<p>目前的深度学习领域就是海量的数据加上大量的数学运算，所以计算量相当的大，训练一个模型跑上十天半个月啥的是常事。那此时分布式的意义就出现了，既然一张GPU卡跑得太慢就来两张，一台机器跑得太慢就用多台机器。</p>
<p><strong>数据并行</strong></p>
<p>![数据并行][1]</p>
]]></summary>
        <content type="html"><![CDATA[<hr>
<p>title: 深度学习框架的并行优化方法小结<br>
date: 2018/8/11 17:38:58</p>
<p>categories:</p>
<ul>
<li>深度学习<br>
tags:</li>
<li>deeplearning</li>
<li>mpi</li>
<li>caffe</li>
</ul>
<hr>
<p>目前的深度学习领域就是海量的数据加上大量的数学运算，所以计算量相当的大，训练一个模型跑上十天半个月啥的是常事。那此时分布式的意义就出现了，既然一张GPU卡跑得太慢就来两张，一台机器跑得太慢就用多台机器。</p>
<p><strong>数据并行</strong></p>
<figure data-type="image" tabindex="1"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1505026360037.jpg" alt="数据并行" loading="lazy"></figure>
<!--more-->
<p>每一个节点（或者叫进程）都有一份模型，然后各个节点取不同的数据，通常是一个batch_size，然后各自完成前向和后向的计算得到梯度，这些进行训练的进程我们成为<strong>worker</strong>，除了worker，还有<strong>参数服务器</strong>，简称ps server，这些worker会把各自计算得到的梯度送到ps server，然后由ps server来进行update操作，然后把update后的模型再传回各个节点。因为在这种并行模式中，被划分的是数据，所以这种并行方式叫<strong>数据并行</strong>。</p>
<p>数据并行有<strong>同步模式和异步模式</strong>之分。同步模式中，所有训练程序同时训练一个批次的训练数据，完成后经过同步，再同时交换参数。参数交换完成后所有的训练程序就有了共同的新模型作为起点，再训练下一个批次。而异步模式中，训练程序完成一个批次的训练数据，立即和参数服务器交换参数，不考虑其他训练程序的状态。异步模式中一个训练程序的最新结果不会立刻体现在其他训练程序中，直到他们进行下次参数交换。</p>
<p><a href="http://blog.csdn.net/xsc_c/article/details/42420167"> 卷积神经网络的并行化模型</a></p>
<h1 id="parameter-server">parameter server</h1>
<p>limu的parameter server， MSRA的adam和google的tensorflow。</p>
<p><a href="https://www.zhihu.com/question/26998075">最近比较火的parameter server是什么？</a></p>
<p><a href="http://www.cs.cmu.edu/~muli/file/ps.pdf">李沐：Parameter Server for Distributed Machine Learning</a></p>
<p>参数服务器是个编程框架，用于方便分布式并行程序的编写，其中重点是对大规模参数的分布式存储和协同的支持。</p>
<p>参数服务器就类似于MapReduce，是大规模机器学习在不断使用过程中，抽象出来的框架之一。重点支持的就是<strong>参数的分布式</strong>，毕竟巨大的模型其实就是巨大的参数。</p>
<h2 id="架构">架构：</h2>
<p>集群中的节点可以分为<strong>计算节点和参数服务节点</strong>两种。其中，计算节点负责对分配到自己本地的训练数据（块）计算学习，并更新对应的参数；参数服务节点采用分布式存储的方式，各自存储全局参数的一部分，并作为服务方接受计算节点的参数查询和更新请求。简而言之吧，计算节点负责干活和更新参数，参数服务节点则负责存储参数。</p>
<h2 id="冗余和恢复">冗余和恢复：</h2>
<p>类似MapReduce，每个参数在参数服务器的集群中都在多个不同节点上备份（<strong>3个</strong>也是极好的），这样当出现节点失效时，冗余的参数依旧能够保证服务的有效性。当有新的节点插入时，把原先失效节点的参数从冗余参数那边复制过来，失效节点的接班人就加入队伍了。</p>
<h2 id="并行计算">并行计算：</h2>
<p>并行计算这部分主要在计算节点上进行。 类似于MapReduce，分配任务时，会将数据拆分给每个worker节点。参数服务器在开始学习前，也会把大规模的训练数据拆分到每个计算节点上。单个计算节点就对本地数据进行学习就可以了。学习完毕再把参数的更新梯度上传给对应的参数服务节点进行更新。</p>
<h2 id="流程">流程</h2>
<p>1.分发训练数据 -&gt; 节点1 节点2   节点3   ... 节点i  ... 节点N<br>
2.节点i 学习过程：遍历本地的训练数据，统计所有需要的参数(key)向分布式的参数服务器查询需要的参数（注意，本地数据对应到的参数只是全局参数的一小部分）得到查询到的参数值，用于模型的本地训练一轮训练完毕，得到所有对应参数的更新，将更新上传给参数服务器<br>
3.参数服务器更新参数过程：参数服务器得到计算节点传过来的局部更新，<strong>汇总后更新本地数据</strong></p>
<h1 id="并行程序">并行程序</h1>
<h2 id="并行实现实现方式">并行实现实现方式：</h2>
<ol>
<li>任务并行：将任务分配带若干计算核上;</li>
<li><strong>数据并行</strong>：将数据进行分割，然后由不同的计算核进行处理，<strong>每个核在规模相当的数据集上大致采用相同的操作</strong>。这不由使我想到了<strong>CAFFE中的对GPU的运用来实现并行训练</strong>的思路，就是将数据集进行分割，每个GPU并行处理各自对应的数据集。</li>
</ol>
<p>多指令多数据流又分为分布式内存系统和共享内存系统。<br>
<strong>分布式内存系统</strong>：<br>
每个处理器由独立的内存，通过<strong>消息传递函数</strong>来通信。<br>
共享式内存系统：<br>
多个处理器能访问内存系统中的相同内存，通过共享内存进行通信。<br>
<strong>MPI</strong>就是用来在分布式系统中为各处理器进行消息传递的API。</p>
<p>各个核能够直接访问自己的内存，而运行在不同核之间的进程需要交换内存数据的时候，只能通过消息传递API来实现。消息传递的API至少要提供一个发送函数和接收函数。**进程之间通过它们的序号（rank）**进行识别。</p>
<h2 id="并行程序的流程">并行程序的流程</h2>
<p>a、任务或者<strong>数据划分</strong>，就是要识别出任务中可以进行并行执行的部分。<br>
b、不同任务之间的<strong>通信</strong>;<br>
c、<strong>聚合</strong>，将任务和通信进行集合，聚合成更大的任务;<br>
d、<strong>分配</strong>，将聚合的任务分配到进程或线程中。</p>
<p>1、MPI是进程级别的，通过通信在进程之间进行消息传递。<br>
2、编程模型复杂：<br>
a、需要进行任务划分;<br>
b、通信延迟和负载不均衡;通信延迟很好理解，负载不均衡是因为分布式的系统，每个处理的任务量不同？待进一步的解释 ；<br>
c、可靠性差，一个进程出错，整个程序崩溃。第一感觉就是这简直是MPI的命门。在分布式系统中某一个进程出错是很容易的，为MPI的命运担忧。</p>
<h1 id="通信函数">通信函数</h1>
<h2 id="一般函数">一般函数</h2>
<pre><code class="language-cpp">int MPI_Send (void *buf, int count, MPI_Datatype datatype,int dest, int tag,MPI_Comm comm)
</code></pre>
<p>参数buf为发送缓冲区；count为发送的数据个数；datatype为发送的数据类型；dest为消息的目的地址(进程号)，其取值范围为0到np－1间的整数(np代表通信器comm中的进程数) 或MPI_PROC_NULL；tag为消息标签，其取值范围为0到MPI_TAG_UB间的整数；<strong>comm为通信器</strong></p>
<pre><code class="language-cpp">mpi_recv:接收信息   MPI_Probe：预测一下消息的size
</code></pre>
<h2 id="mpi聚合通信">mpi聚合通信</h2>
<p>collective communication。聚合通信是在通信子中的所有的进程都参与的通信方式。</p>
<h3 id="同步-mpi_barrier">同步 MPI_Barrier</h3>
<p>MPI_Barrier就是这样的一个函数，他确保除非所有的进程同时调用，否则他不会允许任何进程通过这个节点<br>
对于所有的进程来说，聚合通信必然包含了一个<strong>同步点</strong>。也就是说所有的进程必须在他们又一次执行新动作之前都到达某个点。这跟GPU中线程同步的概念很相似，很好理解。</p>
<h3 id="广播">广播</h3>
<p>广播机制：<br>
一个进程将相同的数据发送给通信子中所有的进程。该机制最主要的应用是将输入数据发送给并行程序，或者将<strong>配置参数</strong>发送给所有的进程</p>
<pre><code class="language-cpp">MPI_Bcast(
    void* data,//数据
    int count,//数据个数
    MPI_Datatype datatype,
    int root,//根进程编号
    MPI_Comm communicator)
</code></pre>
<h3 id="mpi_scatter-数据分发">MPI_Scatter 数据分发</h3>
<p>MPI_Scatter与MPI_Bcast非常相似，都是<strong>一对多</strong>的通信方式，不同的是后者的<strong>0号进程</strong>将相同的信息发送给所有的进程，而前者则是将一段array 的不同部分发送给所有的进程</p>
<figure data-type="image" tabindex="2"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1502761049076.jpg" alt="scatter与bcast的区别" loading="lazy"></figure>
<pre><code class="language-cpp">MPI_Scatter(
    void* send_data,//存储在0号进程的数据，array
    int send_count,//具体需要给每个进程发送的数据的个数
    //如果send_count为1，那么每个进程接收1个数据；如果为2，那么每个进程接收2个数据
    MPI_Datatype send_datatype,//发送数据的类型
    void* recv_data,//接收缓存，缓存 recv_count个数据
    int recv_count,
    MPI_Datatype recv_datatype,
    int root,//root进程的编号
    MPI_Comm communicator)
</code></pre>
<p>通常send_count等于array的元素个数除以进程个数。</p>
<h3 id="mpi_gather">MPI_Gather</h3>
<p>MPI_Gather和MPI_scatter刚好相反，他的作用是从所有的进程中将每个进程的数据集中到根进程中，<strong>同样根据进程的编号对array元素排序</strong></p>
<figure data-type="image" tabindex="3"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1502761558789.jpg" alt="mpi_gather" loading="lazy"></figure>
<pre><code class="language-cpp">MPI_Gather(
    void* send_data,
    int send_count,
    MPI_Datatype send_datatype,
    void* recv_data,
    int recv_count,//注意该参数表示的是从单个进程接收的数据个数，不是总数
    MPI_Datatype recv_datatype,
    int root,
    MPI_Comm communicator)
</code></pre>
<h3 id="mpi_allgather-多对多通信">MPI_Allgather 多对多通信</h3>
<p>当数据分布在所有的进程中时，MPI_Allgather将所有的数据聚合到每个进程中。</p>
<figure data-type="image" tabindex="4"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1502761637900.jpg" alt="mpi_Allgather" loading="lazy"></figure>
<h2 id="数据归约-reduce">数据归约 Reduce</h2>
<p>Reduce——规约是来自函数式编程的一个经典概念。数据规约包含通过一个函数将一批数据分成较小的一批数据。比如将一个数组的元素通过加法函数规约为一个数字。</p>
<h3 id="mpi_reduce">mpi_reduce</h3>
<p>与MPI_Gather类似，MPI_Reduce在每个进程上都有一组输入元素，并将<strong>一个输出元素数组返回给根进程</strong>。 输出元素包含被规约的结果。</p>
<pre><code class="language-cpp">MPI_Reduce(
    void* send_data,
    void* recv_data,
    int count,
    MPI_Datatype datatype,
    MPI_Op op,
    int root,
    MPI_Comm communicator)
</code></pre>
<blockquote>
<p>send_data参数指向的是每个进程想要规约的datatype类型的元素数组。<br>
recv_data仅与根进程相关。<br>
recv_data数组包含规约的结果，并具有sizeof（datatype）* count的大小的内存。<br>
op参数是要应用于数据的操作。</p>
</blockquote>
<p>mpi支持的操作有</p>
<blockquote>
<p>MPI_MAX - 返回最大值.<br>
MPI_MIN - 返回最小值.<br>
MPI_SUM -元素和.<br>
MPI_PROD - 元素乘积.<br>
MPI_LAND - 逻辑与.<br>
MPI_LOR - 逻辑或<br>
MPI_BAND -按位与<br>
MPI_BOR - 按位或<br>
MPI_MAXLOC - 返回最大值和拥有该值的进程编号<br>
MPI_MINLOC - 返回最小值和拥有该值的进程编号.```</p>
</blockquote>
<p>如果每个进程中的数组拥有两个元素，那么规约结果是对两个对位的元素进行规约的。</p>
<figure data-type="image" tabindex="5"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1502762764619.jpg" alt="两个元素的归约结果" loading="lazy"></figure>
<h3 id="mpi_allreduce">mpi_allReduce</h3>
<figure data-type="image" tabindex="6"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1502762804609.jpg" alt="归约后分发给所有的进程" loading="lazy"></figure>
<h1 id="parameter-server-2">parameter-server</h1>
<h1 id="cuda-c编程">CUDA C编程</h1>
<h2 id="cuda运行时函数">cuda运行时函数</h2>
<p>cuda运行时提供了丰富的函数，功能涉及设备管理、存储管理、数据传输、线程管理、流管理、事件管理、纹理管理、执行控制等。</p>
<h3 id="设备管理函数">设备管理函数</h3>
<p>函数声明一般这样</p>
<pre><code>extern __host__ cudaError_t CUDARTAPI 函数名(参数列表)
</code></pre>
<p><strong>cudaGetDeviceCount</strong><br>
获得计算能力大于等于1.0的GPU数量</p>
<pre><code class="language-cpp">int count;
cudaGetDeviceCount(&amp;count);
</code></pre>
<p><strong>cudaSetDevice</strong><br>
设置使用的GPU索引号，如果不设置默认使用0号GPU</p>
<pre><code class="language-cpp">int gpuid = 0;
cudaSetDevice(gpuid);

</code></pre>
<p><strong>cudaGetDevice</strong><br>
获得当前线程的GPU设备号</p>
<pre><code class="language-cpp">int gpuid;
cudaGetDevice(&amp;gpuid);

</code></pre>
<p><strong>cudaSetValidDevices</strong></p>
<p>设置多个device,len表示签名设备号数组的长度;</p>
<pre><code class="language-cpp">cudaSetValidDevices(int &amp;device_arr, int len);
</code></pre>
<h3 id="存储管理函数">存储管理函数</h3>
<p><strong>cudaMalloc</strong></p>
<p>在GPU上分配大小为size的现行存储空间，起始地址为 *devPtr</p>
<pre><code class="language-cpp">cudaMalloc(void **devPtr,size_t size);

</code></pre>
<p><strong>cudaMallocPitch</strong></p>
<p>在GPU上分配大小为PitchxHight的逻辑2D线性存储空间，首地址为<code>*devPtr</code>, 其中Pitch是返回的width对齐后的存储空间的宽度</p>
<pre><code class="language-cpp">cudaMallocPitch(void **devPtr, size_t *pitch, size_t width, size_t height);
</code></pre>
<pre><code>devPtr[x] = devPtr[rowid*pitch+column]
</code></pre>
<p><strong>cudaFree</strong><br>
清空指定的GPU存储区域，可释放cudaMalloc和cudaMallocPitch分类的GPU存储区域</p>
<pre><code class="language-cpp">cudaFree(void *devPtr);

</code></pre>
<p><strong>cudaMemset</strong><br>
将GPU端的devPtr指针指向的count长度的存储空间赋值为value.</p>
<pre><code class="language-cpp">cudaMemset(void 8DevPTR， int value,size_t count);
</code></pre>
<p><strong>cudaHostAlloc</strong><br>
在主机端(CPU)根据flag值来分配页锁定存储,</p>
<pre><code class="language-cpp">cudaHostAlloc(void **pHost, size_t size, usigned int flags);
</code></pre>
<p>flags可以有四种取值</p>
<pre><code class="language-cpp">cudaHostAllocDefault   分配默认存储
cudaHostAllocPortable  分配的存储可以被cuda索引
cudaHostAllocMapped 分配的存储映射到GPU
。。。

</code></pre>
<h3 id="数据传输函数">数据传输函数</h3>
<p><strong>cudaMemcpy</strong></p>
<pre><code class="language-cpp">cudaMemcpy(void * dst, const void *src, size_t count, enum cudaMemcpyKind kind);
</code></pre>
<p>主机(cpu内存)与设备间的数据传输函数，源地址是<code>*src</code>，目标地址是<code>*dst</code>,传输长度为<code>count</code>,kind指定了传输的方向，kind可选值域如下：</p>
<pre><code class="language-cpp">cudaMemcpyHostToHost = 0;
cudaMemcpyHostToDevice = 0;
cudaMemcpyDeviceToHost = 0;
cudaMemcpyDeviceToDevice = 0;
</code></pre>
<p>还有其它的形式</p>
<h3 id="线程管理函数">线程管理函数</h3>
<p><strong>cudaThreadSynchronize</strong></p>
<p>CPU与GPU之间的同步函数，保证该函数前的CPU和GPU上的任务均执行完成，并在该函数位置汇合。一般是CPU在该函数处等待GPU函数执行完。</p>
<pre><code class="language-cpp">cudaThreadSynchronize(void);
</code></pre>
<h1 id="reference">reference</h1>
<p>《GPU编程与优化》——方民权</p>
<h1 id="reference-2">reference</h1>
<p><a href="http://blog.csdn.net/sinat_22336563/article/details/69486937">MPI学习笔记之并行程序概述</a></p>
<p><a href="http://blog.csdn.net/xsc_c/article/details/42420167"> 卷积神经网络的并行化模型</a></p>
<p><a href="https://www.zhihu.com/search?type=content&amp;q=parameter+server">知乎 parameter server</a></p>
<p><a href="http://blog.csdn.net/xbinworld/article/details/74781605">分布式机器学习系统笔记（一）——模型并行，数据并行，参数平均，ASGD</a></p>
<p><a href="http://djt.qq.com/article/view/1245">深度学习及并行化实现概述</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CI进阶]]></title>
        <id>https://DragonFive.github.io/post/ci-advance/</id>
        <link href="https://DragonFive.github.io/post/ci-advance/">
        </link>
        <updated>2018-08-10T04:08:57.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>title: CI进阶<br>
date: 2018/8/9 22:04:12<br>
tags:</p>
<ul>
<li>持续集成</li>
<li>自动化测试</li>
<li>虚拟化</li>
</ul>
<hr>
<h1 id="ci好用的一些runner">CI好用的一些runner</h1>
<p>ssh ： runner中指定远端机器，传artifacts需要在远端安装gitlab-runner<br>
docker：runner中指定image</p>
<h1 id="ci好用的一些variable">CI好用的一些variable</h1>
<p>CI_PROJECT_NAME: 项目名称<br>
CI_PROJECT_PATH: 项目在本地的相对路径</p>
<h1 id="ci的触发条件">CI的触发条件</h1>
<pre><code class="language-YAML">when always
only
  - master
</code></pre>
<h1 id="ci的并行化">CI的并行化</h1>
<h2 id="ci-runner-基于docker的安装">CI-runner 基于docker的安装</h2>
<pre><code class="language-bash">docker run -d --name gitlab-runner --restart always \
-v $(pwd)/config:/etc/gitlab-runner \
gitlab/gitlab-runner:latest
</code></pre>
<h1 id="ci的监控与可视化">CI的监控与可视化</h1>
<h1 id="reference">reference</h1>
<p><a href="https://docs.gitlab.com/runner/install/docker.html">gitlab-ci docker installation</a></p>
<p><a href="https://docs.gitlab.com/runner/configuration/advanced-configuration.html">advanced-configuration</a></p>
<p><a href="https://docs.gitlab.com/runner/monitoring/">GitLab Runner monitoring</a></p>
<p><a href="https://docs.gitlab.com/ee/user/project/integrations/prometheus.html">Prometheus integration</a></p>
<p><a href="https://about.gitlab.com/2017/01/05/prometheus-and-gitlab/">prometheus-and-gitla</a></p>
<p><a href="https://docs.gitlab.com/ee/user/project/integrations/prometheus_library/metrics.html">Prometheus Metrics library</a></p>
<p>[Project services](</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker 用 dockerfile 制作镜像]]></title>
        <id>https://DragonFive.github.io/post/dockerfile/</id>
        <link href="https://DragonFive.github.io/post/dockerfile/">
        </link>
        <updated>2018-07-23T08:13:37.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>title: docker 用 dockerfile 制作镜像<br>
date: 2018/7/23 22:04:12<br>
tags:</p>
<ul>
<li>虚拟化</li>
<li>容器</li>
</ul>
<hr>
<p>Docker 是近年来非常火的容器技术，而且Docker不仅仅是红帽和Canonical等Linux巨头眼里的宠儿，微软等专有软件公司也在热烈拥抱 Docker，可想而知 Docker技术有多么火了。</p>
<h1 id="docker与nvidia-docker的安装">docker与nvidia-docker的安装</h1>
<p><a href="https://blog.csdn.net/a632189007/article/details/78662741">ubuntu安装docker</a><br>
<a href="https://blog.csdn.net/A632189007/article/details/78801166">Nvidia-Docker安装使用 -- 可使用GPU的Docker容器</a><br>
具体安装方法参考<a href="https://github.com/NVIDIA/nvidia-docker">官方github文档</a><br>
值得注意的是上面的教程都是针对 nvidia-docker 1.0版本的，而最近我测试安装时不成功的，所以我安装了最新的nvidia-docker 2.0, nvidia-docker 2.0要求docker 版本为 18.06.0-ce，而这个版本的docker 使用apt-get 是无法安装的，所以我们从官网手动下载deb文件，进行安装。</p>
<p><a href="https://download.docker.com/linux/ubuntu/dists/trusty/pool/stable/amd64/">docker 各版本下载位置</a></p>
<p>卸载老版本的docker</p>
<pre><code class="language-bash">apt-get remove docker-ce
</code></pre>
<p>下载安装新版本的docker</p>
<pre><code class="language-bash">wget https://download.docker.com/linux/ubuntu/dists/trusty/pool/stable/amd64/docker-ce_18.06.0~ce~3-0~ubuntu_amd64.deb 
dpkg -i docker-ce_18.06.0~ce~3-0~ubuntu_amd64.deb  
rm docker-ce_18.06.0~ce~3-0~ubuntu_amd64.deb  
</code></pre>
<p>然后安装nvidia-docker的github的方式安装nvidia-docker-2.</p>
<h1 id="使用dockerfile制作docker镜像">使用dockerfile制作docker镜像</h1>
<p>Dockerfile的指令根据作用可以分为两种，<strong>构建指令和设置指令</strong>。</p>
<ul>
<li>构建指令用于构建image，其指定的操作不会在运行image的容器上执行；</li>
<li>设置指令用于设置image的属性，其指定的操作将在运行image的容器中执行。</li>
</ul>
<h2 id="构建指令">构建指令</h2>
<p><strong>FROM（指定基础image）</strong><br>
必须指定且需要在Dockerfile其他指令的前面。</p>
<pre><code class="language-YAML">FROM 镜像名:标签名
</code></pre>
<p><strong>MAINTAINER（用来指定镜像创建者信息）</strong></p>
<pre><code class="language-YAML">MAINTAINER 作者名
</code></pre>
<p><strong>RUN（安装软件用）</strong><br>
RUN可以运行任何被基础image支持的命令。如基础image选择了ubuntu，那么软件管理部分只能使用ubuntu的命令。</p>
<pre><code class="language-YAML">RUN &lt;command&gt; (the command is run in a shell - /bin/sh -c)
RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot; ... ] 
</code></pre>
<p>** CMD（设置container启动时执行的操作）**</p>
<pre><code class="language-YAML">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]
</code></pre>
<p><strong>ENV（用于设置环境变量）</strong><br>
ENV指令可以用于为docker容器设置环境变量,ENV设置的环境变量，可以使用docker inspect命令来查看。同时还可以使用docker run --env <key>=<value>来修改环境变量。</p>
<pre><code class="language-YAML">ENV &lt;key&gt; &lt;value&gt;
</code></pre>
<p>** ADD（从src复制文件到container的dest路径）**<br>
如果是一个目录，那么会将该目录下的所有文件添加到container中，不包括目录；如果文件是可识别的压缩格式，则docker会帮忙解压缩（注意压缩格式）；如果<src>是文件且<dest>中不使用斜杠结束，则会将<dest>视为文件，<src>的内容会写入<dest>；如果<src>是文件且<dest>中使用斜杠结束，则会<src>文件拷贝到<dest>目录下。</p>
<pre><code class="language-YAML">ADD &lt;src&gt; &lt;dest&gt;
</code></pre>
<ul>
<li><src> 是相对被构建的源目录的相对路径，可以是文件或目录的路径，也可以是一个远程的文件url;</li>
<li><dest> 是container中的绝对路径</li>
</ul>
<p>** COPY(复制本地主机的src文件为container的dest) **<br>
复制本地主机的src文件（为Dockerfile所在目录的相对路径、文件或目录 ）到container的dest。目标路径不存在时，会自动创建。</p>
<pre><code class="language-YAML">COPY &lt;src&gt; &lt;dest&gt;
</code></pre>
<p>当使用本地目录为源<strong>目录</strong>时，推荐使用COPY</p>
<h2 id="构建镜像">构建镜像</h2>
<p>使用当前目录的 Dockerfile 创建镜像，标签为 runoob/ubuntu:v1。</p>
<pre><code class="language-YAML">docker build -t runoob/ubuntu:v1 .
</code></pre>
<h2 id="安装脚本">安装脚本</h2>
<pre><code class="language-YAML">echo &quot;install gfortran&quot;
apt-get install -y gfortran
export LDFLAGS=-L/usr/lib/gcc/x86_64-linux-gnu/4.7/
echo &quot;install open blas&quot;
git clone git://github.com/xianyi/OpenBLAS
cd OpenBLAS &amp;&amp; make FC=gfortran &gt;/dev/null &amp;&amp; make PREFIX=/usr/local install ; cd -
apt-get install -y libopenblas-base
#apt-get install libgtest-dev
#cd /usr/src/gtest &amp;&amp; cmake . &amp;&amp; cmake --build . &amp;&amp; mv libg* /usr/local/lib/ ; cd -

</code></pre>
<p><a href="https://www.jianshu.com/p/af1731a6d033">安装gtest</a></p>
<p><a href="https://mirror.tuna.tsinghua.edu.cn/help/pypi/">清华pypi镜像站</a><br>
<a href="https://blog.csdn.net/aBlueMouse/article/details/78145802">ubuntu安装gcc5.4</a></p>
<p><a href="https://blog.csdn.net/greenlight_74110/article/details/78350196">编译glibc(gcc)以及过程中遇到的一些错误</a></p>
<p><a href="https://blog.csdn.net/u010900574/article/details/52201808">安装cudnn</a></p>
<h2 id="dockerfile-例子">dockerfile 例子</h2>
<pre><code class="language-YAML">FROM gitlabci/cuda8.0_gcc4.9:latest
MAINTAINER maxiaolong maxiaolong@sensetime.com

# install gfortran
ADD sources.list /etc/apt/sources.list
RUN apt-get update
RUN apt-get install -y gfortran
RUN export LDFLAGS=-L/usr/lib/gcc/x86_64-linux-gnu/4.7/
RUN echo &quot;install open blas&quot;
RUN git clone git://github.com/xianyi/OpenBLAS
#RUN cd /OpenBLAS &amp;&amp; make FC=gfortran &gt;/dev/null &amp;&amp; make PREFIX=/usr/local install &amp;&amp; cd -
RUN apt-get install -y libopenblas-base
# set gcc4.8
RUN rm /usr/bin/gcc &amp;&amp; ln -s /usr/bin/gcc-4.8 /usr/bin/gcc
# install GTest
RUN apt-get install -y cmake wget unzip
RUN git clone https://github.com/google/googletest.git
RUN cd googletest/googletest &amp;&amp;  cmake . &amp;&amp;  make
RUN mkdir /usr/local/gtest &amp;&amp; cp -r googletest/googletest /usr/local/gtest/gtest-4.8
# install nccl
RUN git clone https://github.com/NVIDIA/nccl.git
RUN cd nccl  &amp;&amp; make install -j4

# install cudnn
COPY cudnn-8.0-linux-x64-v6.0.tgz cudnn-8.0-linux-x64-v6.0.tgz
RUN tar zxvf cudnn-8.0-linux-x64-v6.0.tgz &amp;&amp; cp cuda/include/cudnn.h /usr/local/cuda/include &amp;&amp; cp cuda/lib64/libcudnn* /usr/local/cuda/lib64 &amp;&amp; chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*

# install gcc5.4
RUN wget http://ftp.gnu.org/gnu/m4/m4-1.4.18.tar.gz  &amp;&amp; gunzip m4-1.4.18.tar.gz &amp;&amp; tar -xvf m4-1.4.18.tar &amp;&amp; cd m4-1.4.18/ &amp;&amp;  ./configure &amp;&amp; make &amp;&amp; make install

RUN wget https://gmplib.org/download/gmp/gmp-6.1.2.tar.xz &amp;&amp; tar -Jxvf gmp-6.1.2.tar.xz &amp;&amp; mkdir temp &amp;&amp; cd temp &amp;&amp; ../gmp-6.1.2/configure --prefix=/usr/local/gmp-6.1.2  &amp;&amp; make &amp;&amp; make install

Run wget https://www.mpfr.org/mpfr-3.1.6/mpfr-3.1.6.zip &amp;&amp;  unzip mpfr-3.1.6.zip &amp;&amp; rm -rf temp &amp;&amp; mkdir temp &amp;&amp; cd temp &amp;&amp; ../mpfr-3.1.6/configure --prefix=/usr/local/mpfr-3.1.6 --with-gmp=/usr/local/gmp-6.1.2 &amp;&amp; make &amp;&amp; make install


RUN wget https://ftp.gnu.org/gnu/mpc/mpc-1.0.3.tar.gz &amp;&amp; tar -zxvf mpc-1.0.3.tar.gz &amp;&amp; rm -rf temp &amp;&amp; mkdir temp &amp;&amp; cd temp &amp;&amp; ../mpc-1.0.3/configure --prefix=/usr/local/mpc-1.0.3 --with-gmp=/usr/local/gmp-6.1.2 --with-mpfr=/usr/local/mp
fr-3.1.6 &amp;&amp; make &amp;&amp; make install

RUN unset LIBRARY_PATH &amp;&amp; wget ftp://ftp.mirrorservice.org/sites/sourceware.org/pub/gcc/releases/gcc-5.4.0/gcc-5.4.0.tar.gz &amp;&amp;  tar -zxvf gcc-5.4.0.tar.gz &amp;&amp; rm -rf temp &amp;&amp; mkdir temp &amp;&amp; cd temp &amp;&amp; ../gcc-5.4.0/configure --prefix=/usr/lo
cal/gcc-5.4 --enable-threads=posix --disable-checking --disable-multilib --enable-languages=c,c++ --with-gmp=/usr/local/gmp-6.1.2 --with-mpfr=/usr/local/mpfr-3.1.6 --with-mpc=/usr/local/mpc-1.0.3 &amp;&amp; make &amp;&amp; make install

RUN rm -rf /temp/
# set the gcc


# install python and pip
RUN apt-get install -y python2.7 python-pip python3.5 python3-pip python-dev python3-dev python3.5-dev cython libhdf5-dev python-numpy python3-numpy build-essential
RUN cd /usr/bin &amp;&amp; rm python3 &amp;&amp; ln -s python3.5 python3
RUN pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pytest-runner flake8 colorlog pyyaml numpy
RUN pip install -i https://pypi.tuna.tsinghua.edu.cn/simple cython requests setuptools --upgrade
RUN pip install h5py

RUN pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple pytest-runner flake8 colorlog pyyaml
RUN pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy cython requests setuptools --upgrade
RUN pip3 install h5py


RUN cd /OpenBLAS &amp;&amp; make FC=gfortran &gt;/dev/null &amp;&amp; make PREFIX=/usr/local install &amp;&amp; cd -
# make the gtest for gcc5.4

RUN rm /usr/bin/gcc &amp;&amp; ln -s /usr/local/gcc-5.4/bin/gcc /usr/bin/gcc

RUN mkdir temp &amp;&amp; cd temp &amp;&amp;  git clone https://github.com/google/googletest.git &amp;&amp; cd googletest/googletest &amp;&amp; cmake . &amp;&amp; make &amp;&amp; cd .. &amp;&amp; cp -r googletest /usr/local/gtest/gtest-5.4

RUN rm -rf temp &amp;&amp; rm /usr/bin/gcc &amp;&amp; ln -s /usr/bin/gcc-4.8 /usr/bin/gcc
</code></pre>
<h2 id="cuda9-cudnn-7">cuda9 + cudnn 7</h2>
<pre><code class="language-YAML">FROM registry.sensetime.com/jiangbo/cuda9_ubuntu16.04:opencv
MAINTAINER maxiaolong maxiaolong@sensetime.com

# install gfortran
ADD sources.list /etc/apt/sources.list
RUN apt-get update
RUN apt-get install -y gfortran
RUN export LDFLAGS=-L/usr/lib/gcc/x86_64-linux-gnu/4.7/
RUN echo &quot;install open blas&quot;
RUN git clone git://github.com/xianyi/OpenBLAS
#RUN cd /OpenBLAS &amp;&amp; make FC=gfortran &gt;/dev/null &amp;&amp; make PREFIX=/usr/local install &amp;&amp; cd -
RUN apt-get install -y libopenblas-base
# set gcc4.8
RUN rm /usr/bin/gcc &amp;&amp; ln -s /usr/bin/gcc-4.8 /usr/bin/gcc
# install GTest
RUN apt-get install -y cmake wget unzip
RUN git clone https://github.com/google/googletest.git
RUN cd googletest/googletest &amp;&amp;  cmake . &amp;&amp;  make
RUN mkdir /usr/local/gtest &amp;&amp; cp -r googletest/googletest /usr/local/gtest/gtest-4.8
# install nccl
RUN git clone https://github.com/NVIDIA/nccl.git
RUN cd nccl  &amp;&amp; make install -j4

# install cudnn
COPY cudnn-7.0.tgz cudnn-7.0.tgz
RUN tar zxvf cudnn-7.0.tgz &amp;&amp; cp cuda/include/cudnn.h /usr/local/cuda/include &amp;&amp; cp cuda/lib64/libcudnn* /usr/local/cuda/lib64 &amp;&amp; chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*

# install gcc5.4
RUN wget http://ftp.gnu.org/gnu/m4/m4-1.4.18.tar.gz  &amp;&amp; gunzip m4-1.4.18.tar.gz &amp;&amp; tar -xvf m4-1.4.18.tar &amp;&amp; cd m4-1.4.18/ &amp;&amp;  ./configure &amp;&amp; make &amp;&amp; make install

RUN wget https://gmplib.org/download/gmp/gmp-6.1.2.tar.xz &amp;&amp; tar -Jxvf gmp-6.1.2.tar.xz &amp;&amp; mkdir temp &amp;&amp; cd temp &amp;&amp; ../gmp-6.1.2/configure --prefix=/usr/local/gmp-6.1.2  &amp;&amp; make &amp;&amp; make install

Run wget https://www.mpfr.org/mpfr-3.1.6/mpfr-3.1.6.zip &amp;&amp;  unzip mpfr-3.1.6.zip &amp;&amp; rm -rf temp &amp;&amp; mkdir temp &amp;&amp; cd temp &amp;&amp; ../mpfr-3.1.6/configure --prefix=/usr/local/mpfr-3.1.6 --with-gmp=/usr/local/gmp-6.1.2 &amp;&amp; make &amp;&amp; make install


RUN wget https://ftp.gnu.org/gnu/mpc/mpc-1.0.3.tar.gz &amp;&amp; tar -zxvf mpc-1.0.3.tar.gz &amp;&amp; rm -rf temp &amp;&amp; mkdir temp &amp;&amp; cd temp &amp;&amp; ../mpc-1.0.3/configure --prefix=/usr/local/mpc-1.0.3 --with-gmp=/usr/local/gmp-6.1.2 --with-mpfr=/usr/local/mp
fr-3.1.6 &amp;&amp; make &amp;&amp; make install

RUN unset LIBRARY_PATH &amp;&amp; wget ftp://ftp.mirrorservice.org/sites/sourceware.org/pub/gcc/releases/gcc-5.4.0/gcc-5.4.0.tar.gz &amp;&amp;  tar -zxvf gcc-5.4.0.tar.gz &amp;&amp; rm -rf temp &amp;&amp; mkdir temp &amp;&amp; cd temp &amp;&amp; ../gcc-5.4.0/configure --prefix=/usr/lo
cal/gcc-5.4 --enable-threads=posix --disable-checking --disable-multilib --enable-languages=c,c++ --with-gmp=/usr/local/gmp-6.1.2 --with-mpfr=/usr/local/mpfr-3.1.6 --with-mpc=/usr/local/mpc-1.0.3 &amp;&amp; make &amp;&amp; make install

RUN rm -rf /temp/
# set the gcc


# install python and pip
RUN apt-get install -y python2.7 python-pip python3.5 python3-pip python-dev python3-dev python3.5-dev cython libhdf5-dev python-numpy python3-numpy build-essential
RUN cd /usr/bin &amp;&amp; rm python3 &amp;&amp; ln -s python3.5 python3
RUN pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pytest-runner flake8 colorlog pyyaml numpy
RUN pip install -i https://pypi.tuna.tsinghua.edu.cn/simple cython requests setuptools --upgrade
RUN pip install h5py

RUN pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple pytest-runner flake8 colorlog pyyaml
RUN pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy cython requests setuptools --upgrade
RUN pip3 install h5py

RUN cd /OpenBLAS &amp;&amp; make FC=gfortran &gt;/dev/null &amp;&amp; make PREFIX=/usr/local install &amp;&amp; cd -

# make the gtest for gcc5.4
RUN rm /usr/bin/gcc &amp;&amp; ln -s /usr/local/gcc-5.4/bin/gcc /usr/bin/gcc
RUN mkdir temp &amp;&amp; cd temp &amp;&amp;  git clone https://github.com/google/googletest.git &amp;&amp; cd googletest/googletest &amp;&amp; cmake . &amp;&amp; make &amp;&amp; cd .. &amp;&amp; cp -r googletest /usr/local/gtest/gtest-5.4
RUN rm -rf temp &amp;&amp; rm /usr/bin/gcc &amp;&amp; ln -s /usr/bin/gcc-4.8 /usr/bin/gcc

</code></pre>
<h1 id="reference">reference</h1>
<p><a href="https://www.jianshu.com/p/cbce69c7a52f">使用Dockerfile构建Docker镜像</a></p>
<p>[Docker build 命令](</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CI从入门到放弃]]></title>
        <id>https://DragonFive.github.io/post/ci-intro/</id>
        <link href="https://DragonFive.github.io/post/ci-intro/">
        </link>
        <updated>2018-07-13T04:10:10.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>title: CI从入门到放弃<br>
date: 2018/7/13 22:04:12<br>
tags:</p>
<ul>
<li>持续集成</li>
<li>自动化测试</li>
<li>虚拟化</li>
</ul>
<hr>
<h1 id="introduce-to-gitlab-ci">Introduce to GitLab CI</h1>
<p>GitLab CI(Continuous Integration )从GitLab8.0开始就集成于GitLab中，后端的Runner使用.gitlab-ci.yml file 文件来描述对项目进行配置，.gitlab-ci.yml文件告诉GitLab运行器该做什么。 默认情况下，它运行一个包含三个stage的pipeline：构建，测试和部署。 你不需要使用所有三个stage; 没有job的stage会被忽略。</p>
<blockquote>
<p>here's a growing trend to use continuous delivery and continuous deployment to automatically deploy tested code to staging and production environments.</p>
</blockquote>
<p>运行一个CI需要有两步操作：</p>
<ol>
<li>将.gitlab-ci.yml添加到存储库的根目录</li>
<li>配置一个Runner</li>
</ol>
<h1 id="write-a-gitlab-ciyml">Write a .gitlab-ci.yml</h1>
<p>.gitlab-ci.yml文件是您配置CI对项目执行的操作的位置。 它位于存储库的根目录中。在任何推送到您的存储库时，GitLab将查找.gitlab-ci.yml文件，并根据该文件的内容在Runners上启动该提交的Job。</p>
<blockquote>
<p>注意：.gitlab-ci.yml是一个YAML文件，所以你必须特别注意缩进。 始终使用空格，而不是制表符。</p>
</blockquote>
<h2 id="jobs">jobs</h2>
<p>YAML文件定义了一组具有约束的job，说明应该何时运行它们。 您可以将job的顶级元素定义为任意名称，它们至少需要包含script子句。</p>
<pre><code class="language-bash">job1:
  script: &quot;execute-script-for-job1&quot;

job2:
  script: &quot;execute-script-for-job2&quot;
</code></pre>
<p><strong>job内的关键字</strong></p>
<table>
<thead>
<tr>
<th>关键字</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>script</td>
<td>由shell执行的脚本</td>
</tr>
<tr>
<td>stage</td>
<td>job的stage，默认为test</td>
</tr>
<tr>
<td>variables</td>
<td>job可见的环境变量</td>
</tr>
<tr>
<td>allow_failure</td>
<td>是否运行job失败</td>
</tr>
<tr>
<td>when</td>
<td>什么情况下执行job，可选on_success/on_failure/always/manual</td>
</tr>
<tr>
<td>only/except/tags</td>
<td>只在某些分支下执行job,指定执行job</td>
</tr>
<tr>
<td>artifacts</td>
<td>job完成后把文件存在这个目录里</td>
</tr>
<tr>
<td>dependencies</td>
<td>依赖的job，可以用artifacts进行共享文件</td>
</tr>
<tr>
<td>coverage</td>
<td>？</td>
</tr>
<tr>
<td>before_script</td>
<td>覆盖在job之前执行的一组命令</td>
</tr>
</tbody>
</table>
<h2 id="stages">stages</h2>
<pre><code class="language-YAML">stages:
  - build
  - test
  - deploy
</code></pre>
<p>stages指定了各个stage的执行顺序</p>
<ol>
<li>同一stage的job是并行运行的。</li>
<li>下一stage的job在上一stage的job成功完成后运行。</li>
</ol>
<h2 id="artifacts">artifacts</h2>
<p>artifacts指的是成功后应附加到job的文件和目录列表。job成功完成后，artifact将被发送到GitLab，并可在GitLab UI中下载</p>
<p>** artifacts:paths**:路径</p>
<p>**artifacts:expire_in ** 有效时间，默认为30天</p>
<h2 id="dependencies">dependencies</h2>
<p>此功能应与artifact结合使用，并允许您定义要在不同job之间传递的artifact。请注意，默认情况下会传递所有先前阶段的artifact。</p>
<h1 id="在ci中使用docker">在CI中使用docker</h1>
<p>Docker与GitLab CI一起使用时，使用.gitlab-ci.yml中设置的预定义镜像在单独且隔离的容器中运行每个job。</p>
<h2 id="register-a-docker-runner">register a docker runner</h2>
<p>使用sudo权限输入</p>
<pre><code class="language-bash">sudo gitlab-runner register
</code></pre>
<p>接下来会提示输入gitlab仓库位置，tocken，以及使用的执行器，使用docker的话执行器就选择docker，然后选择镜像，这个配置以后可以通过修改配置文件进行修改，如果是通过root权限注册的，那么配置文件在/etc/gitlab-runner/config.toml文件中。</p>
<p>使用docker镜像的时候，默认是会从docker-hub下载镜像，如果镜像在本地，可以在config文件设置pull的policy：pull_policy = &quot;if-not-present&quot;或者pull_policy = &quot;never&quot;</p>
<pre><code class="language-YAML">[[runners]]
  name = &quot;&quot;
  url = &quot;&quot;
  token = &quot;&quot;
  executor = &quot;docker&quot;
  [runners.docker]
    tls_verify = false
    image = &quot;nb-node&quot;
    privileged = false
    disable_cache = false
    volumes = [&quot;/cache&quot;]
+   pull_policy = &quot;if-not-present&quot;
  [runners.cache]
</code></pre>
<h2 id="安装docker-和-nvidia-docker">安装docker 和 nvidia-docker</h2>
<p><a href="https://blog.csdn.net/a632189007/article/details/78662741">ubuntu安装docker</a><br>
<a href="https://blog.csdn.net/A632189007/article/details/78801166">Nvidia-Docker安装使用 -- 可使用GPU的Docker容器</a><br>
具体安装方法参考<a href="https://github.com/NVIDIA/nvidia-docker">官方github文档</a></p>
<p>值得注意的是上面的教程都是针对 nvidia-docker 1.0版本的，而最近我测试安装时不成功的，所以我安装了最新的nvidia-docker 2.0, nvidia-docker 2.0要求docker 版本为 18.06.0-ce，而这个版本的docker 使用apt-get 是无法安装的，所以我们从官网手动下载deb文件，进行安装。</p>
<p><a href="https://download.docker.com/linux/ubuntu/dists/trusty/pool/stable/amd64/">docker 各版本下载位置</a></p>
<p>卸载老版本的docker</p>
<pre><code class="language-bash">apt-get remove docker-ce
</code></pre>
<p>下载安装新版本的docker</p>
<pre><code class="language-bash">wget https://download.docker.com/linux/ubuntu/dists/trusty/pool/stable/amd64/docker-ce_18.06.0~ce~3-0~ubuntu_amd64.deb 
dpkg -i docker-ce_18.06.0~ce~3-0~ubuntu_amd64.deb  
rm docker-ce_18.06.0~ce~3-0~ubuntu_amd64.deb  
</code></pre>
<p>然后安装nvidia-docker的github的方式安装nvidia-docker-2.</p>
<h2 id="docker自定义远端仓库位置">docker自定义远端仓库位置</h2>
<p><a href="https://blog.csdn.net/xs20691718/article/details/53213870">docker切换默认镜像源</a><br>
默认安装的 docker 镜像源是在国外，pull 镜像的时候奇慢无比，需要自己手动切换成国内的镜像源。<br>
docker 默认的配置文件是 <code>/etc/default/docker</code>，如果此目录下不存在 docker 文件，可以自己手动创建一个，将文件中添加内容：</p>
<pre><code class="language-YAML"> DOCKER_OPTS=&quot; --registry-mirror=https://【xxxxx】.mirror.aliyuncs.com&quot; 
</code></pre>
<p>上述代码中的地址替换成自己想要更换的镜像源的地址即可，然后使用 service docker restart命令重启服务。<br>
自定义的仓库可能需要通过 docker login 进行登录。</p>
<p>可以参考<a href="https://docs.gitlab.com/ee/ci/docker/using_docker_images.html#define-an-image-from-a-private-container-registry">define-an-image-from-a-private-container-registry</a></p>
<p>如果要将私有docker仓库用作构建的镜像源，可以在DOCKER_AUTH_CONFIG秘密变量中设置授权配置。 它可以在项目的GitLab变量部分(网页端)和config.toml文件中设置。</p>
<figure data-type="image" tabindex="1"><img src="./_image/2018-07-18-10-34-34.jpg" alt="" loading="lazy"></figure>
<h2 id="在ci中定义镜像和服务">在CI中定义镜像和服务</h2>
<pre><code class="language-YAML">before_script:
  - bundle install

test:2.1:
  image: ruby:2.1
  services:
  - postgres:9.3
  script:
  - bundle exec rake spec

test:2.2:
  image: ruby:2.2
  services:
  - postgres:9.4
  script:
  - bundle exec rake spec
</code></pre>
<p><a href="https://blog.csdn.net/aixiaoyang168/article/details/72168834">gitlabCI runner的结合使用例子</a></p>
<h2 id="ci-手动调docker回传artifact-的一个例子">CI 手动调docker回传artifact 的一个例子</h2>
<pre><code class="language-YAML">#image: cicuda8

build_arti:
  stage: build
  tags:
    - manual_docker
  script: 
    - hostname
    - mkdir build &amp;&amp; cd build
    - touch tmp
    - echo &quot;cd hostbuild &amp;&amp; echo hello-world &gt; tmp2&quot; &gt; tmp
  artifacts:
    expire_in: 1 day
    paths:
    - build/

test_arti:
  stage: test
  tags:
    - manual_docker
  script: 
    - sudo docker run --name test_manual_docker -i \
      -v $(pwd)/build:/hostbuild cicuda8 sh /hostbuild/tmp
    - sudo docker rm test_manual_docker
  dependencies:
    - build_arti
  artifacts:
    expire_in: 1 day
    paths:
    - build/
    
deploy_arti:
  stage: deploy
  tags:
    - manual_docker
  script:
    - cd build
    - cat tmp2
    - echo &quot;end4&quot;
  dependencies:
    - test_arti

</code></pre>
<h2 id="ci通过ssh连接来调docker的例子">CI通过SSH连接来调docker的例子</h2>
<pre><code class="language-YAML">#image: cicuda8

build_arti:
  stage: build
  tags:
    - manual_docker
  script: 
    - hostname
    - mkdir build &amp;&amp; cd build
    - touch tmp
    - echo &quot;cd hostbuild &amp;&amp; echo hello-world &gt; tmp2&quot; &gt; tmp
  artifacts:
    expire_in: 1 day
    paths:
    - build/

test_arti:
  stage: test
  tags:
    - manual_docker
  script: 
    - cp /usr/share/expect_login.sh expect_login.sh
    - echo &quot;send \&quot;sudo docker run --name test_manual_docker -i -v $(pwd)/build:/hostbuild cicuda8 sh /hostbuild/tmp\r\&quot;&quot; &gt;&gt; expect_login.sh
    - echo &quot;expect $*&quot; &gt;&gt; expect_login.sh
    - echo &quot;send \&quot;sudo docker rm test_manual_docker\r\&quot;&quot; &gt;&gt; expect_login.sh
    - echo &quot;expect $*&quot; &gt;&gt; expect_login.sh
    - cat expect_login.sh
    - expect expect_login.sh 10.10.36.34
    #- sudo docker run --name test_manual_docker -i -v $(pwd)/build:/hostbuild cicuda8 sh /hostbuild/tmp
    #- sudo docker rm test_manual_docker
  dependencies:
    - build_arti
  artifacts:
    expire_in: 1 day
    paths:
    - build/
    
deploy_arti:
  stage: deploy
  tags:
    - manual_docker
  script:
    - cd build
    - cat tmp2
    - echo &quot;end6&quot;
  dependencies:
    - test_arti


</code></pre>
<p>这里使用了expect脚本：expect_login.sh</p>
<pre><code class="language-YAML">#!/usr/bin/expect
set timeout 30
set ip [lindex $argv 0]
spawn ssh -l maxiaolong 10.0.8.241
expect &quot;password:&quot;
send &quot;mxl@lt.776688\r&quot;
expect &quot;Ip:*&quot;
send &quot;$ip\r&quot;
expect &quot;$*&quot;
send &quot;hostname\r&quot;
expect $*
send ifconfig\r
expect &quot;$*&quot;
#interact

</code></pre>
<h2 id="第二个例子-本地执行docker">第二个例子 本地执行docker</h2>
<pre><code class="language-YAML">stages:
  - build-default2
  - lint
  - test-default
  - build-more
  - test-more
  - build-python-full
  - test-python-full

build-default2:
  stage: build-default2
  variables:
    CC: &quot;/usr/bin/gcc-4.8&quot;
    CXX: &quot;/usr/bin/g++-4.8&quot;
    GTEST_ROOT: &quot;/usr/local/gtest/gtest-4.8&quot;
  tags:
    - manual_docker
  script:
    - mkdir temp &amp;&amp; cd temp &amp;&amp; touch scripts.sh mylog.log
    - git clone $CI_REPOSITORY_URL
    - echo &quot;cd /temp &amp;&amp; export CC=/usr/bin/gcc-4.8 &amp;&amp; export CXX=/usr/bin/g++-4.8 &amp;&amp; export GTEST_ROOT=/usr/local/gtest/gtest-4.8 &quot; &gt;&gt; scripts.sh
    - echo &quot;cd $CI_PROJECT_NAME	&quot; &gt;&gt; scripts.sh
    - echo &quot;git checkout $CI_COMMIT_REF_NAME&quot; &gt;&gt; scripts.sh
    - echo &quot;mkdir build &amp;&amp; cd build/ &amp;&amp; cmake ..  &amp;&amp; make -j8 &quot; &gt;&gt; scripts.sh
    - echo &quot;cd ../python &amp;&amp; make -j8 &quot; &gt;&gt; scripts.sh
    - cat scripts.sh
    - cd -
    - sudo nvidia-docker run -i --rm  -v $(pwd)/temp:/temp  cicuda8:parrots2 sh /temp/scripts.sh
    - cat temp/mylog.log

</code></pre>
<h2 id="第三个例子-上海集群执行docker">第三个例子 上海集群执行docker</h2>
<pre><code class="language-YAML">stages:
  - build-default
  - lint
  - test-default
  - build-more
  - test-more
  - build-python-full
  - test-python-full

build-default:
  stage: build-default
  variables:
    CC: &quot;/usr/bin/gcc-4.8&quot;
    CXX: &quot;/usr/bin/g++-4.8&quot;
    GTEST_ROOT: &quot;/usr/local/gtest/gtest-4.8&quot;
  tags:
    - ssh_docker
  script:
    - hostname
    - who -m
    - mkdir temp &amp;&amp; cd temp &amp;&amp; touch scripts.sh
    - echo &quot;cd /$CI_PROJECT_NAME &amp;&amp; export CC=/usr/bin/gcc-4.8 &amp;&amp; export CXX=/usr/bin/g++-4.8 &amp;&amp; export GTEST_ROOT=/usr/local/gtest/gtest-4.8 &quot; &gt;&gt; scripts.sh
    - echo &quot;cd $CI_PROJECT_NAME	&amp;&amp; hostname &amp;&amp; pwd &quot; &gt;&gt; scripts.sh
    - echo &quot;mkdir build &amp;&amp; cd build/ &amp;&amp; cmake ..  &amp;&amp; make -j8 &quot; &gt;&gt; scripts.sh
    - echo &quot;cd ../python &amp;&amp; make -j8 &quot; &gt;&gt; scripts.sh
    - cat scripts.sh
    - cd -
    - nvidia-docker run -i --rm  -v $(pwd):/$CI_PROJECT_NAME  registry.sensetime.com/platform/cicuda8:parrots2 sh /$CI_PROJECT_NAME/temp/scripts.sh


</code></pre>
<h1 id="configure-a-runner">Configure a Runner</h1>
<p>在GitLab中，Runners运行您在.gitlab-ci.yml中定义的作业。 Runner可以是虚拟机，VPS，裸机，docker容器甚至是容器集群。<br>
get more information at <a href="https://docs.gitlab.com/runner/">GitLab Runner</a>.</p>
<h1 id="reference">reference</h1>
<p><a href="https://blog.csdn.net/sahusoft/article/details/7388617">&quot;error while loading shared libraries: xxx.so.x&quot; 错误的原因和解决办法</a><br>
<a href="https://docs.gitlab.com/runner/executors/docker.html#workflow">the docker excutor</a><br>
<a href="https://docs.gitlab.com/ee/ci/docker/using_docker_images.html#define-image-and-services-from-gitlab-ciyml">Using Docker images</a><br>
<a href="https://docs.gitlab.com/ee/ci/quick_start/README.html">Getting started with GitLab CI/CD</a><br>
[Configuration of your jobs with .gitlab-ci.yml](</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[基于知识迁移的深度神经网络压缩方法研究]]></title>
        <id>https://DragonFive.github.io/post/networker-thransfer/</id>
        <link href="https://DragonFive.github.io/post/networker-thransfer/">
        </link>
        <updated>2018-05-20T03:40:48.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>title: 基于知识迁移的深度神经网络压缩方法研究<br>
date: 2018/5/20 12:04:12<br>
tags:</p>
<ul>
<li>神经网络压缩</li>
<li>深度学习</li>
<li>神经网络</li>
</ul>
<hr>
<p>我的毕设题目是基于知识迁移的深度神经网络压缩方法研究，由于本文涉及实验室的后续研究与项目开发，暂时删除该内容，等待时机合适再公开</p>
<p>——待续</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gluon学习笔记]]></title>
        <id>https://DragonFive.github.io/post/gluon-study/</id>
        <link href="https://DragonFive.github.io/post/gluon-study/">
        </link>
        <updated>2018-03-20T03:39:08.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>title: gluon学习笔记<br>
date: 2018/3/20 12:04:12<br>
categories:</p>
<ul>
<li>深度学习<br>
tags:</li>
<li>目标检测</li>
<li>深度学习</li>
<li>神经网络</li>
</ul>
<hr>
<h1 id="学到的新知识">学到的新知识</h1>
<h2 id="bn放在relu后面">bn放在relu后面</h2>
<p><a href="http://minibatch.net/2017/06/11/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87-Batch-Normalization/">BN应该放在relu后</a></p>
<p><a href="https://mp.weixin.qq.com/s/xJromD5Q30KlRhB_kM4kfA">用于分类、检测和分割的移动网络 MobileNetV2</a></p>
<p><a href="https://www.zhihu.com/question/265709710">如何评价MobileNetV2</a></p>
<h2 id="卷积核的数量">卷积核的数量</h2>
<p><a href="http://zh.gluon.ai/chapter_convolutional-neural-networks/cnn-scratch.html">卷积神经网络 — 从0开始</a></p>
<p>当输入数据有多个通道的时候，每个通道会有对应的权重，然后会对每个通道做卷积之后在通道之间求和。所以当输出只有一个的时候，卷积的channel数目和data的channel数目是一样的。</p>
<p>当输出需要多通道时，每个输出通道有对应权重，然后每个通道上做卷积。所以当输入有n个channel，输出有h个channel时，卷积核channel数目为n * h，每个输出channel对应一个bias ,卷积核的维度为(h,n,w,h)</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mo>(</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo>)</mo><mo>[</mo><mo>:</mo><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mo>:</mo><mo separator="true">,</mo><mo>:</mo><mo>]</mo><mo>=</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mo>(</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo separator="true">,</mo><mi>w</mi><mo>[</mo><mi>i</mi><mo separator="true">,</mo><mo>:</mo><mo separator="true">,</mo><mo>:</mo><mo separator="true">,</mo><mo>:</mo><mo>]</mo><mo separator="true">,</mo><mi>b</mi><mo>[</mo><mi>i</mi><mo>]</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">conv(data, w, b)[:,i,:,:] = conv(data, w[i,:,:,:], b[i])
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mopen">(</span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mopen">[</span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mopen">(</span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mclose">]</span><span class="mclose">)</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Γ</mi><mo>(</mo><mi>z</mi><mo>)</mo><mo>=</mo><msubsup><mo>∫</mo><mn>0</mn><mi mathvariant="normal">∞</mi></msubsup><msup><mi>t</mi><mrow><mi>z</mi><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>e</mi><mrow><mo>−</mo><mi>t</mi></mrow></msup><mi>d</mi><mi>t</mi><mtext> </mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt\,.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Γ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.326242em;vertical-align:-0.9119499999999999em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.414292em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span></span></span></span></span></p>
<p>123</p>
<figure data-type="image" tabindex="1"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1513949196873.jpg" alt="inception v1" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1514013854016.jpg" alt="residual" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://www.github.com/DragonFive/CVBasicOp/raw/master/1514012389756.jpg" alt="resnet各种结构" loading="lazy"></figure>
<h1 id="gluon语法">gluon语法</h1>
<h2 id="nnblock与nnsequential的嵌套使用">nn.Block与nn.sequential的嵌套使用</h2>
<pre><code class="language-python">class RecMLP(nn.Block):
    def __init__(self, **kwargs):
        super(RecMLP, self).__init__(**kwargs)
        self.net = nn.Sequential()
        with self.name_scope():
            self.net.add(nn.Dense(256, activation=&quot;relu&quot;))
            self.net.add(nn.Dense(128, activation=&quot;relu&quot;))
            self.dense = nn.Dense(64)

    def forward(self, x):
        return nd.relu(self.dense(self.net(x)))

rec_mlp = nn.Sequential()
rec_mlp.add(RecMLP())
rec_mlp.add(nn.Dense(10))
print(rec_mlp)
</code></pre>
<h2 id="初始化与参数访问">初始化与参数访问</h2>
<pre><code class="language-python">from mxnet import init
params.initialize(init=init.Normal(sigma=0.02), force_reinit=True)
print(net[0].weight.data(), net[0].bias.data())
</code></pre>
<p>我们也可以通过collect_params来访问Block里面所有的参数（这个会包括所有的子Block）。它会返回一个名字到对应Parameter的dict。</p>
<p>也可以自定义各层的初始化方法，没有自定义的按照net.initialize里面的方法进行定义</p>
<pre><code class="language-python">from mxnet.gluon import nn
from mxnet import nd
from mxnet import init

def get_net():
    net = nn.Sequential()
    with net.name_scope():
        net.add(nn.Dense(4,activation=&quot;relu&quot;))#,weight_initializer=init.Xavier()))
        net.add(nn.Dense(2,weight_initializer=init.Zero(),bias_initializer=init.Zero()) )
    return net

x = nd.random.uniform(shape=(3,5))
net = get_net()
net.initialize(init.One())
net(x)
print(net[1].weight.data
</code></pre>
<h2 id="gpu访问">GPU访问</h2>
<ol>
<li>删除cpu版本mxnet</li>
</ol>
<pre><code class="language-bash">pip uninstall mxnet
</code></pre>
<ol start="2">
<li>更新GPU版本mxnet</li>
</ol>
<pre><code class="language-bash">pip install -U --pre mxnet-cu80
</code></pre>
<ol start="3">
<li>查看版本号</li>
</ol>
<pre><code class="language-python">import pip
for pkg in ['mxnet', 'mxnet-cu75', 'mxnet-cu80']:
    pip.main(['show', pkg])
</code></pre>
<h2 id="使用jupyter的相关插件">使用jupyter的相关插件</h2>
<ol>
<li>notedown插件<br>
可以在jupyter 中查看markdown文件</li>
<li>nb_conda<br>
是conda的插件，可以在jupyter里面修改python内核版本</li>
</ol>
<h2 id="优化方法">优化方法</h2>
<p><strong>momentum</strong><br>
gluon.Trainer的learning_rate属性和set_learning_rate函数可以随意调整学习率。</p>
<pre><code class="language-python">trainer = gluon.Trainer(net.collect_params(), 'sgd',
                            {'learning_rate': lr, 'momentum': mom})
</code></pre>
<p><strong>adagrad</strong><br>
Adagrad是一个在迭代过程中不断自我调整学习率，并让模型参数中每个元素都使用不同学习率的优化算法。</p>
<pre><code class="language-python">    trainer = gluon.Trainer(net.collect_params(), 'adagrad',
                            {'learning_rate': lr})
</code></pre>
<p><strong>Adam</strong></p>
<pre><code class="language-python">trainer = gluon.Trainer(net.collect_params(), 'adam',
                            {'learning_rate': lr})

</code></pre>
<p>通过以上分析, 理论上可以说, 在数据比较稀疏的时候, adaptive 的方法能得到更好的效果, 例如, adagrad, adadelta, rmsprop, adam 等. 在数据稀疏的情况下, adam 方法也会比 rmsprop 方法收敛的结果要好一些, 所以, 通常在没有其它更好的理由的前框下, 我会选用 adam 方法, 可以比较快地得到一个预估结果. 但是, 在论文中, 我们看到的大部分还是最原始的 mini-batch 的 SGD 方法. 因为马鞍面的存在等问题, SGD 方法有时候较难收敛. 另外, SGD 对于参数的初始化要求也比较高. 所以, 如果要是想快速收敛的话, 建议使用 adam 这类 adaptive 的方法</p>
<h2 id="延迟执行">延迟执行</h2>
<p>延后执行使得系统有更多空间来做性能优化。但我们推荐每个批量里至少有一个同步函数，例如对损失函数进行评估，来避免将过多任务同时丢进后端系统。</p>
<pre><code class="language-python">from mxnet import autograd

mem = get_mem()

total_loss = 0
for x, y in get_data():
    with autograd.record():
        L = loss(y, net(x))
    total_loss += L.sum().asscalar()
    L.backward()
    trainer.step(x.shape[0])

nd.waitall()
print('Increased memory %f MB' % (get_mem() - mem))

</code></pre>
<h2 id="多gpu训练">多GPU训练</h2>
<pre><code class="language-python">ctx = [gpu(i) for i in range(num_gpus)]
data_list = gluon.utils.split_and_load(data, ctx)
label_list = gluon.utils.split_and_load(label, ctx)



</code></pre>
<h2 id="fintune-微调">fintune 微调</h2>
<p><a href="https://fiercex.github.io/post/gluon_features_fine/">gluon微调</a></p>
<h1 id="一些可以重复使用的代码">一些可以重复使用的代码</h1>
<h2 id="读取数据">读取数据</h2>
<pre><code class="language-python">from mxnet import gluon
from mxnet import ndarray as nd

def transform(data, label):
    return data.astype('float32')/255, label.astype('float32')
mnist_train = gluon.data.vision.FashionMNIST(train=True, transform=transform)
mnist_test = gluon.data.vision.FashionMNIST(train=False, transform=transform)

</code></pre>
<h2 id="计算精度">计算精度</h2>
<pre><code class="language-python">def accuracy(output, label):
    return nd.mean(output.argmax(axis=1)==label).asscalar()


</code></pre>
<p>我们先使用Flatten层将输入数据转成 batch_size x ? 的矩阵，然后输入到10个输出节点的全连接层。照例我们不需要制定每层输入的大小，gluon会做自动推导。</p>
<h2 id="激活函数">激活函数</h2>
<p><strong>sigmoid</strong></p>
<pre><code class="language-python">from mxnet import nd
def softmax(X):
    exp = nd.exp(X)
    # 假设exp是矩阵，这里对行进行求和，并要求保留axis 1，
    # 就是返回 (nrows, 1) 形状的矩阵
    partition = exp.sum(axis=1, keepdims=True)
    return exp / partition


</code></pre>
<p><strong>relu</strong></p>
<pre><code class="language-python">def relu(X):
    return nd.maximum(X, 0)

</code></pre>
<h2 id="损失函数">损失函数</h2>
<p><strong>平方误差</strong></p>
<pre><code class="language-python">square_loss = gluon.loss.L2Loss()


</code></pre>
<pre><code class="language-python">def square_loss(yhat, y):
    # 注意这里我们把y变形成yhat的形状来避免矩阵形状的自动转换
    return (yhat - y.reshape(yhat.shape)) ** 2
 

</code></pre>
<p><strong>交叉熵损失</strong></p>
<pre><code class="language-python">def cross_entropy(yhat, y):
    return - nd.pick(nd.log(yhat), y)

</code></pre>
<pre><code class="language-python">softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()

</code></pre>
<h2 id="取一个batch_size的代码">取一个batch_size的代码</h2>
<p><strong>scratch版本</strong></p>
<pre><code class="language-python">import random
batch_size = 1
def data_iter(num_examples):
    idx = list(range(num_examples))
    random.shuffle(idx)
    for i in range(0, num_examples, batch_size):
        j = nd.array(idx[i:min(i+batch_size,num_examples)])
        yield X.take(j), y.take(j)

</code></pre>
<p><strong>gluon版本</strong></p>
<pre><code class="language-python">batch_size = 1
dataset_train = gluon.data.ArrayDataset(X_train, y_train)
data_iter_train = gluon.data.DataLoader(dataset_train, batch_size, shuffle=True)



</code></pre>
<h2 id="初始化权值">初始化权值</h2>
<p><strong>scratch版本</strong></p>
<pre><code class="language-python">def get_params():
    w = nd.random.normal(shape=(num_inputs, 1))*0.1
    b = nd.zeros((1,))
    for param in (w, b):
        param.attach_grad()
    return (w, b)

</code></pre>
<p><strong>gluon版本</strong></p>
<pre><code class="language-python">net.initialize()


net.collect_params().initialize(mx.init.Normal(sigma=1))

</code></pre>
<h2 id="sgd">SGD</h2>
<p><strong>scratch版本</strong></p>
<pre><code class="language-python">def SGD(params, lr):
    for param in params:
        param[:] = param - lr * param.grad


</code></pre>
<p>L2正则</p>
<pre><code class="language-python">def L2_penalty(w, b):
    return ((w**2).sum() + b**2) / 2

</code></pre>
<p><strong>gluon版本</strong></p>
<pre><code>    trainer = gluon.Trainer(net.collect_params(), 'sgd', {
        'learning_rate': learning_rate, 'wd': weight_decay})

</code></pre>
<p>这里的weight_decay表明这里添加了L2正则，正则化<br>
w = w -lr * grad - wd * w</p>
<h2 id="训练过程">训练过程</h2>
<p><strong>scratch版本</strong></p>
<pre><code class="language-python">    for e in range(epochs):        
        for data, label in data_iter(num_train):
            with autograd.record():
                output = net(data, lambd, *params)
                loss = square_loss(
                    output, label) + lambd * L2_penalty(*params)
            loss.backward()
            SGD(params, learning_rate)
        train_loss.append(test(params, X_train, y_train))
        test_loss.append(test(params, X_test, y_test))

</code></pre>
<p><strong>gluon版本</strong></p>
<pre><code class="language-python">    for e in range(epochs):        
        for data, label in data_iter_train:
            with autograd.record():
                output = net(data)
                loss = square_loss(output, label)
            loss.backward()
            trainer.step(batch_size)            
        train_loss.append(test(net, X_train, y_train))
        test_loss.append(test(net, X_test, y_test))


</code></pre>
<pre><code class="language-python">%matplotlib inline
import matplotlib as mpl
mpl.rcParams['figure.dpi']= 120
import matplotlib.pyplot as plt

def train(X_train, X_test, y_train, y_test):
    # 线性回归模型
    net = gluon.nn.Sequential()
    with net.name_scope():
        net.add(gluon.nn.Dense(1))
    net.initialize()
    # 设一些默认参数
    learning_rate = 0.01
    epochs = 100
    batch_size = min(10, y_train.shape[0])
    dataset_train = gluon.data.ArrayDataset(X_train, y_train)
    data_iter_train = gluon.data.DataLoader(
        dataset_train, batch_size, shuffle=True)
    # 默认SGD和均方误差
    trainer = gluon.Trainer(net.collect_params(), 'sgd', {
        'learning_rate': learning_rate})
    square_loss = gluon.loss.L2Loss()
    # 保存训练和测试损失
    train_loss = []
    test_loss = []
    for e in range(epochs):
        for data, label in data_iter_train:
            with autograd.record():
                output = net(data)
                loss = square_loss(output, label)
            loss.backward()
            trainer.step(batch_size)
        train_loss.append(square_loss(
            net(X_train), y_train).mean().asscalar())
        test_loss.append(square_loss(
            net(X_test), y_test).mean().asscalar())
    # 打印结果
    plt.plot(train_loss)
    plt.plot(test_loss)
    plt.legend(['train','test'])
    plt.show()
    return ('learned weight', net[0].weight.data(),
            'learned bias', net[0].bias.data())

</code></pre>
<p>最终版</p>
<pre><code class="language-python">def train(train_data, test_data, net, loss, trainer, ctx, num_epochs, print_batches=None):
    &quot;&quot;&quot;Train a network&quot;&quot;&quot;
    print(&quot;Start training on &quot;, ctx)
    if isinstance(ctx, mx.Context):
        ctx = [ctx]
    for epoch in range(num_epochs):
        train_loss, train_acc, n, m = 0.0, 0.0, 0.0, 0.0
        if isinstance(train_data, mx.io.MXDataIter):
            train_data.reset()
        start = time()
        for i, batch in enumerate(train_data):
            data, label, batch_size = _get_batch(batch, ctx)
            losses = []
            with autograd.record():
                outputs = [net(X) for X in data]
                losses = [loss(yhat, y) for yhat, y in zip(outputs, label)]
            for l in losses:
                l.backward()
            train_acc += sum([(yhat.argmax(axis=1)==y).sum().asscalar()
                              for yhat, y in zip(outputs, label)])
            train_loss += sum([l.sum().asscalar() for l in losses])
            trainer.step(batch_size)
            n += batch_size
            m += sum([y.size for y in label])
            if print_batches and (i+1) % print_batches == 0:
                print(&quot;Batch %d. Loss: %f, Train acc %f&quot; % (
                    n, train_loss/n, train_acc/m
                ))

        test_acc = evaluate_accuracy(test_data, net, ctx)
        print(&quot;Epoch %d. Loss: %.3f, Train acc %.2f, Test acc %.2f, Time %.1f sec&quot; % (
            epoch, train_loss/n, train_acc/m, test_acc, time() - start
        ))

</code></pre>
<h1 id="reference">reference</h1>
<p><a href="https://zhuanlan.zhihu.com/p/28867241">从零开始码一个皮卡丘检测器</a></p>
<p><a href="http://blog.csdn.net/jesse_mx/article/details/53606897">图片标注工具</a></p>
<p><a href="http://blog.csdn.net/u014696921/article/details/56877979"> mxnet 使用自己的图片数据训练CNN模型</a></p>
<p><a href="https://mxnet.incubator.apache.org/api/python/image.html#Image">mxnet image API</a></p>
<p><a href="https://mxnet.incubator.apache.org/how_to/recordio.html?highlight=recordio">Create a Dataset Using RecordIO</a></p>
<p><a href="http://blog.csdn.net/muyouhang/article/details/77727381">基于MXNet gluon 的SSD模型训练</a></p>
<p><a href="https://groups.google.com/a/continuum.io/forum/m/#!topic/anaconda/RuSpZVPEio8">解决conda与ipython notebook的python版本问题</a></p>
<p><a href="http://blog.csdn.net/sunshine_in_moon/article/details/51434908">神经网络计算参数量的方法</a></p>
<p><a href="https://www.jianshu.com/p/c56a37093cfa">神经网络计算特征图的大小的方法</a></p>
<p><a href="http://minibatch.net/2017/06/11/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87-Batch-Normalization/">BN应该放在relu后</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[linux常用脚本]]></title>
        <id>https://DragonFive.github.io/post/linux-bash/</id>
        <link href="https://DragonFive.github.io/post/linux-bash/">
        </link>
        <updated>2018-02-13T08:15:25.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>title: linux常用工具<br>
date: 2018/2/13 22:04:12<br>
tags:</p>
<ul>
<li>linux</li>
</ul>
<hr>
<p><strong>Expect脚本</strong><br>
安装方法：</p>
<pre><code class="language-bash">sudo apt-get install tcl tk expect

</code></pre>
<p>脚本例子自动SSH连接：</p>
<pre><code class="language-YAML">#!/usr/bin/expect
set timeout 30
set ip [lindex $argv 0]
spawn ssh -l maxiaolong 10.0.8.241
expect &quot;password:&quot;
send &quot;mxl@lt.776688\r&quot;
expect &quot;Ip:*&quot;
send &quot;$ip\r&quot;
expect &quot;$*&quot;
send &quot;hostname\r&quot;
expect &quot;$*&quot;
interact
</code></pre>
<h1 id="gcc升级完整不留遗憾的方法">gcc升级完整不留遗憾的方法</h1>
<p>自己编译安装gcc4.9——&gt;替换软链接——&gt;替换libstdc++.so的软链接</p>
<p>通过下面的命令可以查看Glibcxx的版本</p>
<pre><code class="language-bash"> strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX
</code></pre>
<p>nvidia-docker run -it --rm -v /usr/local/cuda:/usr/local/cuda -v /usr/local/cuda-8.0:/usr/local/cuda-8.0 -v /home/maxiaolong/:/workdir centos:cuda8_gcc4.9.4 bash</p>
<h1 id="linux-使用方法">linux 使用方法</h1>
<p><a href="https://blog.csdn.net/fdipzone/article/details/24329523">生成随机数和随机字符串</a></p>
<p><a href="https://blog.csdn.net/StephenLu0422/article/details/78471551">docker 后台运行</a><br>
<a href="http://blog.sina.com.cn/s/blog_17b46b5e40102xilj.html">docker 非root运行| linux新建用户</a></p>
<p><a href="https://blog.csdn.net/Apollon_krj/article/details/70148022">shell环境变量</a></p>
<p><a href="https://stackoverflow.com/questions/9639103/is-there-a-goto-statement-in-bash">bash实现goto</a><br>
<a href="https://blog.csdn.net/train006l/article/details/79007483">linux 修改用户uid</a></p>
<p><a href="http://daizj.iteye.com/blog/2212559">shell 脚本切换用户执行命令</a></p>
<p>[centos安装gcc4.9.4](</p>
]]></content>
    </entry>
</feed>